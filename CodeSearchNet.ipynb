{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CodeSearchNet Data Source Notice"
      ],
      "metadata": {
        "id": "d3QskDTbwoUM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsyNUB9POBaT",
        "outputId": "b5012ffa-877e-4a49-9b8e-23baeb968616"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/CodeSearchNet’: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir /content/CodeSearchNet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install docopt"
      ],
      "metadata": {
        "id": "C5yUBaR0SA32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After the CodeSearchNet dataset was archieved, the S3 bucket was taken offline. As a result, following the installation on the github installation guide will not work. A short illustration can be seen down below."
      ],
      "metadata": {
        "id": "C2p5D1KzWk_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from subprocess import call, check_call, CalledProcessError\n",
        "\n",
        "destination_dir = \"/content/CodeSearchNet\"\n",
        "\n",
        "if not os.path.exists(destination_dir):\n",
        "    os.makedirs(destination_dir)\n",
        "os.chdir(destination_dir)\n",
        "\n",
        "try:\n",
        "    language = \"python\"\n",
        "    check_call(['wget', f'https://s3.amazonaws.com/code-search-net/CodeSearchNet/v2/{language}.zip', '-O', f'{language}.zip'])\n",
        "    check_call(['unzip', f'{language}.zip'])\n",
        "    check_call(['rm', f'{language}.zip'])\n",
        "except CalledProcessError as e:\n",
        "    print(f\"Error: {e}\")\n",
        "    print(f\"Error executing command {e.cmd}\")\n",
        "    print(f\"Returned code {e.returncode}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgBuEGUIOyB1",
        "outputId": "2eb1de01-f530-4fb2-c1c6-1c93d8e33699"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Command '['wget', 'https://s3.amazonaws.com/code-search-net/CodeSearchNet/v2/python.zip', '-O', 'python.zip']' returned non-zero exit status 8.\n",
            "Error executing command ['wget', 'https://s3.amazonaws.com/code-search-net/CodeSearchNet/v2/python.zip', '-O', 'python.zip']\n",
            "Returned code 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instead, we download the dataset from Hugging Face. Updating `datasets` might not be necessary but might sometimes be helpful to avoid errors concering caching in the local file system"
      ],
      "metadata": {
        "id": "OC_ULT-kXAoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Fetching"
      ],
      "metadata": {
        "id": "yzT8WmsywReH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "%pip install -U datasets"
      ],
      "metadata": {
        "id": "fbljfl0sJDen"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load the dataset\n",
        "dataset = load_dataset(\"code_search_net\", \"python\")\n",
        "\n",
        "train_data = dataset[\"train\"]\n",
        "test_data = dataset[\"test\"]\n",
        "validation_data = dataset[\"validation\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403,
          "referenced_widgets": [
            "74ed7329a0384d4d99e6eedaf7230622",
            "b2d8dd6fcd054ff99eca4e752ae2cabb",
            "95f55b5c982f4767b4e58f846f44688d",
            "13d5e80c871a42edad648c4c9ec84940",
            "20abefb03c0b4f8fab571015c7a4bcc4",
            "e6953d78073f4ce5aea949f963aa7ee5",
            "5b07a311e21d4c3ab1429e280e3ee4f0",
            "13e693bb69e64fc8b0190ec8a5b9039d",
            "36188fac1c784ff4b835a58ba0bcf39a",
            "912a1058c57d46b5a5875efbc1184214",
            "257e1d0890874d0c94e7718f1afb0c5d",
            "40d1803948634b25b3b27021b77541f4",
            "39238ec871384334890d228a94b788ad",
            "8533a401abfa47c2abc09a296a0edc32",
            "247a3517ae694736acfde1fc08f4a4ec",
            "9f1748cd4a954ff7ae0b7f53df452453",
            "ca46431063064d839103e7d8b1b2262d",
            "dba4247f016a4fb4a942c149e00a3717",
            "912d8ab57e034f0895db76962539fad3",
            "31bdca347995491da591ed745beb1916",
            "c519e1352a144569813f09ab28ea1cdb",
            "0a545476c62740e28635e1f0428dc185",
            "711f4c03bcc947deb5268f29bd533444",
            "418c7081ddb645a69fa93ed537022796",
            "7677008063a844e6b435112016af13b0",
            "ac095d164e1c416db345da5483b42e6e",
            "1f2d68aca0e64ad5ac666630f3e8abb3",
            "ac72980671f14b23a54552e46b6cd475",
            "fea747e25de743f5b395c2bb4b8f0a35",
            "b77f8bfdfb6d4cb086c5b8c92bb45e89",
            "67b1bbe4e0bb47adaf5f74f86a6f2ca2",
            "6d823f7de3334c09b6c07953bd0006f1",
            "3eaba0fa33294aa6a3d38f44b1447b6e",
            "44aa6edbfa7d4c4abd55de682172ad61",
            "ad19916f990442579a8c687f09458afd",
            "c9053cb4742c41dfaaf0403c40a13128",
            "216bbf52e0d1412eaf35da5e002b037c",
            "9b21eb2025174775b3ba4ee9677e6eaf",
            "e3201804fb7d4c3fb545f29f88597243",
            "d5ccbbbd8a9145a09d540aa145c7ca4b",
            "527873edcf664705b9b907e8f21d099a",
            "1c22f3bcea1c4a7c8e97f5346b17041a",
            "1c89466911294f19a536df61c8973de6",
            "9f9b061c3b2e4357a08bcc7eb38b5d76",
            "0040f4764a3142ae9b959115a2048e65",
            "cf26ed2fad284cb5ada93d0483a43636",
            "6d555e5f265e4287aeb0cf2087c5252b",
            "fa43130fe714495fa1ea405d2995d608",
            "4f3befe19b4c43018810238fa8cd5884",
            "f0245a1125664783a0b774cc6d003688",
            "506958590dbd4f8c95944158478c0b49",
            "d4fee045b9264fc0a968b2ce42e7d9ee",
            "62a48cf51a7040db9dbba2d3e432a82b",
            "59ba142d4f6f4f3cadc396e89853a2a9",
            "773632cb6be046a49e8d26c18042677d",
            "4aae7a6b62014926884260a10e928cf8",
            "5332ebc819b1414dacaf740f9ef45439",
            "31052ed1005c426d8d7b7d5aa8e2bacf",
            "7f38df48f9ad4a89807600e53b1d7cf5",
            "6ce3e24a96c7420690b1f72f7aa22aaf",
            "535d2af99e2e4d4eb1cd96a3765c6ba7",
            "c5fcf00e128245f394802b05f5683492",
            "1fa90c2fca164f57a51d9d2fff7439d4",
            "a8dceb5090614cf8a70b21a4fb7b3039",
            "1b5d5af9b6d14e4796b54155d90ee8d0",
            "10d7404307024bfb923d075ac08deb67"
          ]
        },
        "id": "5MfdVWN1JELf",
        "outputId": "2def19e2-9d7d-4b97-f183-2a55873f61ba"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "74ed7329a0384d4d99e6eedaf7230622"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "code_search_net.py: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "40d1803948634b25b3b27021b77541f4"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The repository for code_search_net contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/code_search_net.\n",
            "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
            "\n",
            "Do you wish to run the custom code? [y/N] y\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "python.zip:   0%|          | 0.00/941M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "711f4c03bcc947deb5268f29bd533444"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/412178 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "44aa6edbfa7d4c4abd55de682172ad61"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/22176 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0040f4764a3142ae9b959115a2048e65"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/23107 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4aae7a6b62014926884260a10e928cf8"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can inspect the contents of the dataset object for the training, testing, and validation datasets."
      ],
      "metadata": {
        "id": "FQfMMFc3b6vs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.features.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCTJR_45byNv",
        "outputId": "8c59737a-fc69-4b69-ee20-70af4446a7bb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question Generation Pipeline"
      ],
      "metadata": {
        "id": "Ssi7fBcnweX-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    AutoTokenizer,\n",
        "    PreTrainedModel,\n",
        "    PreTrainedTokenizer\n",
        ")\n",
        "from nltk import sent_tokenize\n",
        "\n",
        "from typing import (\n",
        "    Tuple,\n",
        "    Dict,\n",
        "    Literal,\n",
        "    List,\n",
        "    Any,\n",
        "    Generator,\n",
        "    overload,\n",
        "    Union\n",
        ")\n",
        "\n",
        "class QGPipeline:\n",
        "    def __init__(\n",
        "        self,\n",
        "        model: str,\n",
        "        qg_format: Literal[\"highlight\"] = \"highlight\",\n",
        "        exclude_after: List[str] = [],\n",
        "        use_cuda: bool = False\n",
        "    ):\n",
        "\n",
        "        self.model = AutoModelForSeq2SeqLM.from_pretrained(model)\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model)\n",
        "        self.qg_format = qg_format\n",
        "\n",
        "        assert self.model.__class__.__name__ == \"T5ForConditionalGeneration\"\n",
        "\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() and use_cuda else \"cpu\")\n",
        "        self.model.to(self.device)\n",
        "        self.model.eval()\n",
        "        self.use_cuda = use_cuda\n",
        "        self._exclude_after = exclude_after\n",
        "        print(f\"Using {self.device}\")\n",
        "\n",
        "    def __call__(self, input: Union[Tuple[str, str], List[Tuple[str, str]]]):\n",
        "        if isinstance(input, tuple):\n",
        "            # Handle single input\n",
        "            func_name, docstring = input\n",
        "            questions = self._generate_questions(func_name, docstring)\n",
        "            output = [{'answer': func_name, 'question': que} for que in questions]\n",
        "            if output:\n",
        "                 return output[0]\n",
        "            else:\n",
        "                 return {}\n",
        "\n",
        "        elif isinstance(input, list) and all(isinstance(item, tuple) for item in input):\n",
        "            # Handle batch input with proper error handling\n",
        "            return self._process_batch_generator(input)\n",
        "        else:\n",
        "            raise TypeError(\"Invalid input type. Expected a tuple (func_name, docstring) or a list of such tuples.\")\n",
        "\n",
        "\n",
        "    def _process_batch_generator(self, batch_input: List[Tuple[str, str]]) -> Generator[Dict[str, Any], None, None]:\n",
        "        \"\"\"\n",
        "        Process batch input and yield results with error handling per item\n",
        "        \"\"\"\n",
        "        for i, (func_name, docstring) in enumerate(batch_input):\n",
        "            try:\n",
        "                questions = self._generate_questions(func_name, docstring)\n",
        "                output = [{'answer': func_name, 'question': que} for que in questions]\n",
        "\n",
        "                if output:\n",
        "                    yield {\n",
        "                        'success': True,\n",
        "                        'index': i,\n",
        "                        'function_name': func_name,\n",
        "                        'docstring': docstring,\n",
        "                        'model_output': output[0],\n",
        "                        'error': None\n",
        "                    }\n",
        "                else:\n",
        "                    yield {\n",
        "                        'success': False,\n",
        "                        'index': i,\n",
        "                        'function_name': func_name,\n",
        "                        'docstring': docstring,\n",
        "                        'model_output': {},\n",
        "                        'error': 'No questions generated'\n",
        "                    }\n",
        "\n",
        "            except Exception as e:\n",
        "                yield {\n",
        "                    'success': False,\n",
        "                    'index': i,\n",
        "                    'function_name': func_name,\n",
        "                    'docstring': docstring,\n",
        "                    'model_output': {},\n",
        "                    'error': str(e)\n",
        "                }\n",
        "\n",
        "    def _generate_questions(self, func_name, docstring):\n",
        "        #TODO: This can be re-written in a more forceful way for the llm\n",
        "        inputs = self._prepare_inputs_for_question_extraction(func_name, docstring)\n",
        "\n",
        "        inputs = self._tokenize(inputs, padding=True, truncation=True)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outs = self.model.generate(\n",
        "                input_ids=inputs['input_ids'].to(self.device),\n",
        "                attention_mask=inputs['attention_mask'].to(self.device),\n",
        "                num_beams=4,\n",
        "\n",
        "                max_length=32\n",
        "            )\n",
        "\n",
        "        questions = [self.tokenizer.decode(ids, skip_special_tokens=True) for ids in outs]\n",
        "\n",
        "        return questions\n",
        "\n",
        "    def _tokenize(self, inputs, padding=True, truncation=True, add_special_tokens=True, max_length=512):\n",
        "        tokenized_inputs = self.tokenizer(\n",
        "            inputs,\n",
        "            max_length=max_length,\n",
        "            add_special_tokens=add_special_tokens,\n",
        "            truncation=truncation,\n",
        "            padding=padding,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        return tokenized_inputs\n",
        "\n",
        "    def _prepare_inputs_for_question_extraction(self, func_name, docstring):\n",
        "        #NOTE: experimental, consider removing :params and :return values\n",
        "        #manual observation suggests the model struggles to understand the pupose of the function in their presense\n",
        "        for string in self._exclude_after:\n",
        "            param_idx = docstring.find(string)\n",
        "            if param_idx != -1:\n",
        "                docstring = docstring[:param_idx]\n",
        "            docstring = docstring.strip()\n",
        "        input = f\"answer: <hl>The function is {func_name}<hl>. Context: {docstring} </s>\"\n",
        "\n",
        "        return [input]\n",
        "\n",
        "    @property\n",
        "    def exclude_after(self):\n",
        "        return self._exclude_after\n",
        "\n",
        "    @exclude_after.setter\n",
        "    def exclude_after(self, value):\n",
        "        self._exclude_after = value"
      ],
      "metadata": {
        "id": "0jlDE7JajLqk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finetuned_t5 = QGPipeline(model=\"valhalla/t5-base-qg-hl\")"
      ],
      "metadata": {
        "id": "b0DxchuaFNVm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296,
          "referenced_widgets": [
            "c47bf00fe8064cb290e46af1409772c0",
            "0f740830e213411dba959b5f5bfcf14f",
            "8b35af706efb40e986042af28e111193",
            "8953a65f69d4440491bea085b081974d",
            "9c046c7a9e9a4a17bb437d6d2a7a6e6d",
            "8212b00fd68d4a968a78ca469e4b6816",
            "7ebbcdd832e64b378d6149e87c9cd879",
            "fa919c43f614476ca0e6cb7b77974fad",
            "6e0f02c8764e4f3a9efe959ab15faa3d",
            "8cc725f8eb2d469ca583a29cb9c85bdc",
            "08e73e0502e347e6a604950f243b07e0",
            "f774a4b0fe5d4ff2b21d980f3b0fbe22",
            "33508cac9dcd4bc68c720349127fbd52",
            "b510cd3323d54e52b8fa714bccf219e8",
            "adb671dc0e7b4c34a6c5675c9e7c0155",
            "514d62c4c4894e1a83ff4c552bd0da64",
            "6f16f42959be4eb6a237ad945841c555",
            "55dcbccfe54d4b2195df2b3fc6dcaffc",
            "1a5d593ffe7b497689900c65979401c8",
            "e775af4f459a4000b265cefbe6642103",
            "9087657b03d2444bbc53483f623db860",
            "be2c45f2e8124b608ee6bc25666bdc89",
            "76c711d3557341e3bed196245fc0dceb",
            "3cee5a389d5647c1aa7b82391a78d83a",
            "16df15a86a744f508b9966c9351ac5ae",
            "61b31d9976eb4528ba8f301231aa7c05",
            "f50e35b03c514a848a884fc4d0c6d4da",
            "41484af97db34652a3c15c9472bf9a8a",
            "9508c4db28b045a7bc10e41ff772d357",
            "3ac02a7e8c7348c596b24739b95aa497",
            "c412c442bce143e2a59bf723bae6770e",
            "847e271f61d84c3b811b0aa1eba16587",
            "3e95385c088e40759395c935fa6f385a",
            "91b0a27426df488ca8fcf3bb08a5c1fd",
            "bea5fb8b73c94510a5439e55211fb95c",
            "c7f40be1e3b84da98d992d1e17d4eed9",
            "b724b2ff70fa4a199e21c59643acfbfd",
            "f6037b4b9d3746aab89d26c36e330b2a",
            "932f1f989be04ef892155a9b70ae5463",
            "f7a44dc93ea342b481cd7608f01be4ad",
            "8206d0dbcaf942869c393dfd59f9b5bf",
            "4826bf0133cd466da027d0c5b5753dd4",
            "ec04fa5c81fe43a9a5def135d2f3c11d",
            "28a16612fbb94fb7ba84b145a67216d8",
            "5e996213ed42402089641bec72a463d2",
            "81762953581c4ecdb52b0bc396a66763",
            "3485316b6aea4b458521f1d943820919",
            "c41826b5c28140bc9cceab347fde8db7",
            "fe1ce03c4c414133a8df5bcb46e13825",
            "cabf632ce2bf4edf9d626fde10889730",
            "abfa1a8b44af40e7b2f5cc0a106732a0",
            "87523173714241bd9c7ef86ed7b47c90",
            "5e8b4d561d104de181dc5b839adec2dd",
            "e7bf194063fd4194ac7ef28cd8cf95af",
            "be7f42477e1a4a1aaf46bca15b8fb5fb",
            "64f134d5242c436fb4594190dd3d5435",
            "f4dcd4b8766c439bb84937b14607fca3",
            "acaed8fbb56e4cd3ae3de8aa6dea8b70",
            "136875f72afc4a9f89dc1bade21e1d18",
            "1b8d48d2202d49fcbd374505352171a0",
            "6e9fcab7c1bb4b168bc3f22afbd82440",
            "f3b52244b32c43c88f48480aa73c2a9b",
            "a97b34bb154c4d2aaabfc090694ca683",
            "2ae0a2b4754e4f2a97a22de4caaed14c",
            "79dc2846454a41088026c94a640985e5",
            "4a8026e4e5384449bd4266aa3da68b04",
            "1351ba5a1c48469c90a3b29eabba5508",
            "0df2519ed9b946a2a668ba421f9fd436",
            "4b459682457c48f2ba01d887f1f80349",
            "a9b63dbc7e5046e9bfa47877d806624f",
            "ce8f5f42b0694e8584ded3db4ee106a8",
            "fc280d4c02aa4305b746aab2f83f8221",
            "cafd884f589242819c93b167b59ca734",
            "1ebd04aba358490785eebfc36189b910",
            "a7c834c9415d48cb9c50b70b781935e7",
            "6cb4350ea00a403dbb8ac37e7327a036",
            "0f394ff131ac4d229a671f0c07986a9a"
          ]
        },
        "outputId": "b4556c5a-3dab-4503-8322-280da242988c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c47bf00fe8064cb290e46af1409772c0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/892M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f774a4b0fe5d4ff2b21d980f3b0fbe22"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "76c711d3557341e3bed196245fc0dceb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/129 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "91b0a27426df488ca8fcf3bb08a5c1fd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5e996213ed42402089641bec72a463d2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/15.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "64f134d5242c436fb4594190dd3d5435"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1351ba5a1c48469c90a3b29eabba5508"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "func_name = train_data[4]['func_name']\n",
        "docstring = train_data[4]['func_documentation_string']\n",
        "print(docstring)\n",
        "finetuned_t5((func_name, docstring))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4w2QjHhVyhdy",
        "outputId": "4c3bf26a-4aea-400d-c40d-f5aff37fa16e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read a single frame from the connection.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': 'WebSocketCommonProtocol.read_frame',\n",
              " 'question': 'What is the function that reads a single frame from a connection?'}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The result looks promising. Let's run the model for the first 20 doc strings in our dataset"
      ],
      "metadata": {
        "id": "PllIvQOqRx_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "    func_name = train_data[i]['func_name']\n",
        "    p = docstring = train_data[i]['func_documentation_string']\n",
        "    print(f\"========Sample{i+1}==========\")\n",
        "    idx = docstring.find(\":param\")\n",
        "    if idx != -1:\n",
        "        p = docstring[:idx]\n",
        "    p = docstring[:].strip()\n",
        "    print(f\"Docstring: {docstring}\")\n",
        "    print(finetuned_t5(func_name, docstring))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "XB0O656n6lzA",
        "outputId": "db5c1a05-c661-4a6b-9afe-57854f3d99c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========Sample1==========\n",
            "Docstring: Display slug with level by language.\n",
            "[{'answer': 'show_slug_with_level', 'question': 'What is the name of the function that displays a slug with level by language?'}]\n",
            "========Sample2==========\n",
            "Docstring: Render the last 10 revisions of a page content with a list using\n",
            "        the ``pages/revisions.html`` template\n",
            "[{'answer': 'show_revisions', 'question': 'What is the name of the function that shows the last 10 revisions of a page?'}]\n",
            "========Sample3==========\n",
            "Docstring: Method that parse the imageplaceholder template tag.\n",
            "[{'answer': 'do_videoplaceholder', 'question': 'What is the name of the method that parses the imageplaceholder template tag?'}]\n",
            "========Sample4==========\n",
            "Docstring: Return Pages with given tag\n",
            "\n",
            "    Syntax::\n",
            "\n",
            "        {% get_pages_with_tag <tag name> as <varname> %}\n",
            "\n",
            "    Example use:\n",
            "        {% get_pages_with_tag \"footer\" as pages %}\n",
            "[{'answer': 'do_get_pages_with_tag', 'question': 'What is the name of the function that returns pages with given tag?'}]\n",
            "========Sample5==========\n",
            "Docstring: Parses the XML run statistics file (GenerateFASTQRunStatistics.xml). In some cases, the file is not\n",
            "        available. Equivalent data can be pulled from Basespace.Generate a text file  name indexingQC.txt containing\n",
            "        the copied tables from the Indexing QC tab of the run on Basespace\n",
            "[{'answer': 'Metadata.parserunstats', 'question': 'What is the name of the file that parses the XML run statistics file?'}]\n",
            "========Sample6==========\n",
            "Docstring: Prettify name of path\n",
            "\n",
            "    :param path: path to fix\n",
            "    :return: Good name for path\n",
            "[{'answer': 'fix_raw_path', 'question': 'What is the name of the file that is used to fix a path?'}]\n",
            "========Sample7==========\n",
            "Docstring: Removes year from input\n",
            "\n",
            "    :param name: path to edit\n",
            "    :return: inputs with no years\n",
            "[{'answer': 'remove_year', 'question': 'What is the name of the function that removes a year from input?'}]\n",
            "========Sample8==========\n",
            "Docstring: Removes brackets form input\n",
            "\n",
            "    :param name: path to fix\n",
            "    :return: inputs with no brackets\n",
            "[{'answer': 'remove_brackets', 'question': 'What is the name of the function that removes brackets from input?'}]\n",
            "========Sample9==========\n",
            "Docstring: Extracts max chars in name truncated to nearest word\n",
            "\n",
            "    :param name: path to edit\n",
            "    :param max_chars: max chars of new name\n",
            "    :param blank: char that represents the blank between words\n",
            "    :return: Name edited to contain at most max_chars\n",
            "[{'answer': 'extract_name_max_chars', 'question': 'What is the name of the function that extracts maximum chars in name?'}]\n",
            "========Sample10==========\n",
            "Docstring: Prettify name of path\n",
            "\n",
            "    :param name: path Name: to edit\n",
            "    :param blank: default blanks in name\n",
            "    :return: Prettier name from given one: replace bad chars with good ones\n",
            "[{'answer': 'prettify', 'question': 'What is the name of the path that is used to make it easier to find?'}]\n",
            "========Sample11==========\n",
            "Docstring: Finds parent folder of file\n",
            "\n",
            "    :param file_path: path\n",
            "    :return: Name of folder container\n",
            "[{'answer': 'get_parent_folder_name', 'question': 'What is the name of the function that finds the parent folder of a file?'}]\n",
            "========Sample12==========\n",
            "Docstring: Finds content of folder\n",
            "\n",
            "    :param path: directory to get list of files and folders\n",
            "    :param include_hidden: True iff include hidden files in list\n",
            "    :return: List of paths in given directory\n",
            "[{'answer': 'ls_dir', 'question': 'What is the name of the folder that finds the contents of?'}]\n",
            "========Sample13==========\n",
            "Docstring: Finds content of folder recursively\n",
            "\n",
            "    :param path: directory to get list of files and folders\n",
            "    :param include_hidden: True iff include hidden files in list\n",
            "    :return: List of paths in given directory recursively\n",
            "[{'answer': 'ls_recurse', 'question': 'What is the name of the function that finds content of a folder recursively?'}]\n",
            "========Sample14==========\n",
            "Docstring: Finds content of folder (recursively)\n",
            "\n",
            "    :param path: directory to get list of files and folders\n",
            "    :param recurse: True iff recurse into subdirectories or not\n",
            "    :param include_hidden: True iff include hidden files in list\n",
            "    :return: List of paths in given directory recursively\n",
            "[{'answer': 'list_content', 'question': 'What is the name of the file that finds content?'}]\n",
            "========Sample15==========\n",
            "Docstring: Checks if file path is russian\n",
            "\n",
            "        :return: True iff document has a russian name\n",
            "[{'answer': 'FileSystem.is_russian', 'question': 'What is the name of the filesystem?'}]\n",
            "========Sample16==========\n",
            "Docstring: Renames to new path\n",
            "\n",
            "        :param new_path: new path to use\n",
            "[{'answer': 'FileSystem.rename', 'question': 'What is the name of the file system that renames to a new path?'}]\n",
            "========Sample17==========\n",
            "Docstring: This waits until the whole chain of callback methods triggered by\n",
            "        \"trigger_connection_to_rabbit_etc()\" has finished, and then starts \n",
            "        waiting for publications.\n",
            "        This is done by starting the ioloop.\n",
            "\n",
            "        Note: In the pika usage example, these things are both called inside the run()\n",
            "        method, so I wonder if this check-and-wait here is necessary. Maybe not.\n",
            "        But the usage example does not implement a Thread, so it probably blocks during\n",
            "        the opening of the connection. Here, as it is a different thread, the run()\n",
            "        might get called before the __init__ has finished? I'd rather stay on the\n",
            "        safe side, as my experience of threading in Python is limited.\n",
            "[{'answer': 'ConnectionBuilder.__start_waiting_for_events', 'question': 'What is the name of the method that waits until the whole chain of callback methods has finished?'}]\n",
            "========Sample18==========\n",
            "Docstring: Sets the constructor for the component type this label is to \n",
            "        represent\n",
            "\n",
            "        :param factoryclass: a class that, when called, results in an instance of the desired class\n",
            "        :type factoryclass: callable\n",
            "[{'answer': 'DragLabel.setClass', 'question': 'What is the name of the class that sets the constructor for the component type this label is to represent?'}]\n",
            "========Sample19==========\n",
            "Docstring: Determines if a drag is taking place, and initiates it\n",
            "[{'answer': 'DragLabel.mouseMoveEvent', 'question': 'What is the name of the event that determines if a drag is taking place?'}]\n",
            "========Sample20==========\n",
            "Docstring: Enters all the metadata into a database\n",
            "[{'answer': 'Database.database', 'question': 'What is the name of the file that enters all the metadata into a database?'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zipped5 = zip(train_data[:5]['func_name'], train_data[:5]['func_documentation_string'])\n",
        "\n",
        "generator = finetuned_t5(list(zipped5))\n",
        "print(generator)\n",
        "\n",
        "for item in generator:\n",
        "    ans, ques = item['function_name'], item['model_output']['question']\n",
        "    print(f\"========Sample==========\")\n",
        "    print(f\"Question: {ques}\")\n",
        "    print(f\"Answer: {ans}\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "K2Wd_0ByUjFb",
        "outputId": "81ef55b7-3e02-4c17-8c50-4c23c3e6160c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<generator object QGPipeline._process_batch_generator at 0x7833286165c0>\n",
            "========Sample==========\n",
            "Question: What is the function that ensures that the WebSocket connection is open?\n",
            "Answer: WebSocketCommonProtocol.ensure_open\n",
            "\n",
            "========Sample==========\n",
            "Question: What is the function that reads incoming messages and puts them in a queue?\n",
            "Answer: WebSocketCommonProtocol.transfer_data\n",
            "\n",
            "========Sample==========\n",
            "Question: What is the function that reads a single message from the connection?\n",
            "Answer: WebSocketCommonProtocol.read_message\n",
            "\n",
            "========Sample==========\n",
            "Question: What is the function that reads a single data frame from a connection?\n",
            "Answer: WebSocketCommonProtocol.read_data_frame\n",
            "\n",
            "========Sample==========\n",
            "Question: What is the function that reads a single frame from a connection?\n",
            "Answer: WebSocketCommonProtocol.read_frame\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Processor"
      ],
      "metadata": {
        "id": "IPREFUqlXIbu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "from typing import List, Dict, Any\n",
        "from datasets import Dataset, DatasetDict\n",
        "\n",
        "class DocstringDatasetProcessor:\n",
        "    def __init__(self,\n",
        "                 hf_dataset_name: str,\n",
        "                 batch_size: int = 1000,\n",
        "                 token: str = None,\n",
        "                 save_locally: bool = False,\n",
        "                 local_cache_dir: str = \"./cache\",\n",
        "                 private_repo: bool = False):\n",
        "\n",
        "        self.hf_dataset_name = hf_dataset_name\n",
        "        self.batch_size = batch_size\n",
        "        self.private_repo = private_repo\n",
        "        self.local_cache_dir = Path(local_cache_dir)\n",
        "        self.local_cache_dir.mkdir(exist_ok=True)\n",
        "        self.save_locally = save_locally\n",
        "\n",
        "        self.processed_count = 0\n",
        "        self.failed_count = 0\n",
        "        self.all_generated_data = []\n",
        "\n",
        "        self.token = token\n",
        "\n",
        "    def process_batch(self, batch_data: List[Tuple[str, str]], pipeline: QGPipeline, batch_id: int) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Process a batch of (func_name, docstring) tuples with individual error handling\"\"\"\n",
        "        batch_results = []\n",
        "        batch_success_count = 0\n",
        "        batch_failure_count = 0\n",
        "\n",
        "        print(batch_data)\n",
        "\n",
        "        # Process the entire batch through pipeline\n",
        "        try:\n",
        "            generator = pipeline(batch_data)\n",
        "            for result in generator:\n",
        "\n",
        "                if result['success']:\n",
        "                    batch_results.append({\n",
        "                        'function_name': result['function_name'],\n",
        "                        'docstring': result['docstring'],\n",
        "                        'question': result['model_output']['question'],\n",
        "                    })\n",
        "                    batch_success_count += 1\n",
        "                else:\n",
        "                    print(\n",
        "                        f\"Failed to process {result['function_name']}: {result['error']}\"\n",
        "                    )\n",
        "                    batch_failure_count += 1\n",
        "\n",
        "        except Exception as e:\n",
        "            # Catastrophic failure - entire batch failed\n",
        "            print(f\"Catastrophic batch failure {batch_id}: {e}\")\n",
        "            batch_failure_count = len(batch_data)\n",
        "            batch_success_count = 0\n",
        "\n",
        "        self.processed_count += batch_success_count\n",
        "        self.failed_count += batch_failure_count\n",
        "\n",
        "        print(\n",
        "            f\"Batch {batch_id}: {batch_success_count} successful, \"\n",
        "            f\"{batch_failure_count} failed out of {len(batch_data)} items\"\n",
        "        )\n",
        "\n",
        "        if self.save_locally and batch_results:\n",
        "            self._save_batch_locally(batch_results, batch_id)\n",
        "\n",
        "        return batch_results\n",
        "\n",
        "    def _save_batch_locally(self, batch_results: List[Dict], batch_id: int):\n",
        "        batch_file = self.local_cache_dir / f\"batch_{batch_id}.jsonl\"\n",
        "        with open(batch_file, 'w') as f:\n",
        "            for item in batch_results:\n",
        "                json.dump(item, f)\n",
        "                f.write('\\n')\n",
        "\n",
        "    def process_full_dataset(self, dataset, pipeline, start_idx: int = 0):\n",
        "        \"\"\"Process the entire data set and upload to hugging face\"\"\"\n",
        "\n",
        "        print(f\"Starting processing of {len(dataset)} items from index {start_idx}\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        for batch_start in tqdm(range(start_idx, len(dataset), self.batch_size),\n",
        "                                desc=\"Processing batches\"):\n",
        "            batch_end = min(batch_start + self.batch_size, len(dataset))\n",
        "            batch_data = dataset[batch_start:batch_end]\n",
        "            batch_id = batch_start // self.batch_size\n",
        "\n",
        "            batch_results = self.process_batch(batch_data, pipeline, batch_id)\n",
        "            self.all_generated_data.extend(batch_results)\n",
        "\n",
        "            # print progress\n",
        "            if batch_id % 10 == 0:\n",
        "                elapsed = time.time() - start_time\n",
        "                rate = self.processed_count / elapsed if elapsed > 0 else 0\n",
        "                print(f\"Processed {self.processed_count} items in {elapsed:.2f} seconds. Rate: {rate:.2f} items/sec\")\n",
        "\n",
        "            #final statistics\n",
        "            total_time = time.time() - start_time\n",
        "            print(f\"Processed {self.processed_count} items in {total_time:.2f} seconds. Rate: {self.processed_count / total_time:.2f} items/sec\")\n",
        "\n",
        "            self._upload_to_hf()\n",
        "\n",
        "    def _upload_to_hf(self):\n",
        "        if self.token is None:\n",
        "            raise ValueError(\"Hugging Face token not provided\")\n",
        "        try:\n",
        "            print(\"Creating Hugging Face dataset\")\n",
        "\n",
        "            dataset = Dataset.from_list(self.all_generated_data)\n",
        "\n",
        "            dataset_dict = DatasetDict({\n",
        "                'train': dataset\n",
        "            })\n",
        "\n",
        "            #notice this might introduce unneccessary inefficiencies\n",
        "            dataset_dict = dataset_dict.map(\n",
        "                lambda x: {\n",
        "                    **x,\n",
        "                    'id': f\"{x['function_name']}_{hash(x['docstring']) % 10000}\"\n",
        "                }\n",
        "            )\n",
        "\n",
        "            print(f\"Uploading dataset to {self.hf_dataset_name}...\")\n",
        "\n",
        "            dataset_dict.push_to_hub(\n",
        "                self.hf_dataset_name,\n",
        "                token=self.token,\n",
        "                private=self.private_repo,\n",
        "                commit_message=f\"Add {len(self.all_generated_data)} docstring-question pairs\"\n",
        "            )\n",
        "\n",
        "            print(f\"Successfully uploaded dataset to https://huggingface.co/datasets/{self.hf_dataset_name}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error uploading to Hugging Face: {e}\")\n",
        "            if self.save_locally:\n",
        "                print(\"Data is available locally in cached directory\")\n",
        "            raise\n",
        "\n",
        "    def load_from_hf(self):\n",
        "        \"\"\"Load the dataset from Hugging Face\"\"\"\n",
        "\n",
        "        from datasets import load_dataset\n",
        "\n",
        "        try:\n",
        "            dataset = load_dataset(self.hf_dataset_name, token=self.token)\n",
        "            print(f\"Successfully loaded dataset from {self.hf_dataset_name}\")\n",
        "            return dataset\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading dataset from Hugging Face: {e}\")\n",
        "            raise\n",
        "\n",
        "    #TODO: resume processing from local cache file\n",
        "    #TODO: upload from colab cache to permanent file location (local or drive)"
      ],
      "metadata": {
        "id": "_M83XuxNZ2tF"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Constants\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "HUGGING_FACE_TOKEN = userdata.get(\"HUGGING_FACE_TOKEN\")\n",
        "hf_dataset_name = \"mrinjera/testing\""
      ],
      "metadata": {
        "id": "iIDPV8GQvy-C"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_processor = DocstringDatasetProcessor(hf_dataset_name, batch_size=10, token=HUGGING_FACE_TOKEN)\n",
        "\n",
        "batch_raw_data = zip(train_data[:200]['func_name'], train_data[:200]['func_documentation_string'])\n",
        "batch_zip_data = list(batch_raw_data)\n",
        "\n",
        "pipeline = finetuned_t5\n",
        "dataset_processor.process_full_dataset(batch_zip_data, pipeline)"
      ],
      "metadata": {
        "id": "NK5CdGjViK8N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "43753ead9a1b455e855523e3d8571cb8",
            "7b1b2dad439448aca155907174069f2c",
            "fd8a86a6ce0440aa972ac562bae9d84f",
            "12ec4b7f3ee34bebbe38ddc527e55ba4",
            "580d63916cc0437fb14e7ea1f96fd70c",
            "c08c7a6e67ef497291226aec5010b7d0",
            "8745992a4b664bd5b2abfc4ebaa14acf",
            "c758f64a31bf4f3482115eea966611db",
            "b2a05f4ad9564cb5acb654f804357702",
            "31513496c11646b6a9e97949cdb936d1",
            "fbe215620b53445f883a1b3a7f331d17",
            "20a70b26ea2c41df92d5d197393a1b87",
            "3b67d74ebd364b3faaad7b92bbc3cafd",
            "57f1ad4350dd44fc918ac014331a4e0d",
            "ee283b40c82e4af980b95d38838689ae",
            "337fb8d8db9d4c4a9f042c2f280f4e07",
            "e48eb4a44d994491bcf778b4d2e25d57",
            "d25ec91ccac34756b3d2c73dc61ae2b1",
            "6e125a3c2b5140e0baebdba290871ec2",
            "c5e43a75191443448e400bddfee8272f",
            "1fdb5bad4f154d6681f098bd7579eb81",
            "96da8711e9b64f209c9db133658aee81",
            "f939ec2848504f0e89a3ca7fbf630671",
            "b6938b1875b8415d989e0eaa851d6eb0",
            "d1365c8f97a348f0b72b45ca1f10fe97",
            "7f1f94f5cbf04418b1ea74003ff6f4ef",
            "d958a4e56d4749a790a8d9052b7f9294",
            "08083198745a4b39a23028c15ffdd00d",
            "fd0cf5f5523f458fb8419cd51e3c8181",
            "6f90f5c6b9e34c7da76fbd924adaf96a",
            "9f57859ea51a411cb19a7a1b981b4bd9",
            "3f2ea6c1cb2843c3892d430425a2fc70",
            "766887625afc49438439456a9a19efcd",
            "8e8709c2a7434771b5c78e450f59f342",
            "7108d6e2312f42918aa342b8159ea28d",
            "316f233059c44bd7ada1b0f5fa79fa2f",
            "fb372f3c6388421cbd94d1acc8cc8344",
            "69473ec42121436eb8130b00e12b9afb",
            "269a022a68664d16a2873bc08995845c",
            "7c2fe866c74940c98428f35b7df37a61",
            "9488cf3d266b4934909762021d84d9ad",
            "c530e7b912794488ad0e6b2f4d0715f9",
            "d4c04032401644efa39d14431b2b0efc",
            "30ef1110406f47868aa97be08b1157f6",
            "d87b31f113d54b90be00556e38a36798",
            "b83749b106aa4394a86035d1a0604d8c",
            "3f780da874024ca08ebef5158ea8f3dd",
            "fcc10e753b1a4adeb3071467cdd8f96a",
            "69cc51058c374bd5a750a8e1e21313cb",
            "2a8da354ad854fc3b294629df62a65ab",
            "f003e4910d8f4fb9b3ec51830186d5dc",
            "077644313e6d4ea0ab2cb01f0c094378",
            "4134012f304540eba92f6970de7ecc27",
            "16b6d9aca8214b3f82d6481ffacf5e31",
            "ac9075250f544fc280ce1c46202b0fc2",
            "ae49dfac56804be3bf9c99b174fb70a7",
            "09fc4511d7b54dd992b3b4370bd27c6c",
            "baf5ef2542124fbe855f3f4236100316",
            "92bef01d362a43b687cd282a58503d14",
            "b58e8facf4944085a409f2bed8621167",
            "b75a2f18b9a04baeb0ba3faa4bd836ae",
            "98cbb7a0c2ae49d98fe9960d56d03aaa",
            "dbb4ba3d742645ea883ff85ca6d77834",
            "3323cda3382a4a1684885725101a266c",
            "e571e426a2dc453ab91b69da464dcfe4",
            "805d27439e854b55865227dd7954f51c",
            "2fdcc6fc74164ece89e1d218712a0863",
            "59f597a890ba4a449b8d3ec653c2325b",
            "8632cbed58e2492ba8de4c7d0d314cdf",
            "512dace7e5cb427fb8fc68682a26b7c5",
            "7045af9b2ca74afc9b3641a56243c95f",
            "ee4ade9cfc5b4607add9fe390ae1bd9f",
            "df5d23e2f0f04852a9b1a9dbd7c3ab44",
            "880f26bef68145ae923b4efecca86086",
            "762fd68ebe024bbf9617ab9652ec8d7b",
            "64913db5eff2417b819f4df69589d1db",
            "311481d455b347529232964878b09c0e",
            "d3a568a2069242b9b468b38a77caea5c",
            "5b2da0f09f6641cbb6827d55d8ffea04",
            "f5cafc3d201345dca3620832a8f0fe97",
            "0e444c42bb174e3faa63b72af9611861",
            "099aca7264fe4e309a25355277bb7113",
            "9bb37e46feae4173a12866242e04c069",
            "875a25c5fa8c44e1b0709d4c0eea51b0",
            "169a85b983344a9b99b3a754e8889f59",
            "de22b0d6a482444e94c974fccacaa740",
            "6235f6242b3c4a35aa610ee63912ee0d",
            "b9d188e5a77649e0bf3089c5603b8b22",
            "3e16779eb6d541bd8fcc61d77cceab2c",
            "43f40a1f24e54b2bafa301c8c60b4060",
            "d134be001a6a47948c6d75e5567fa9a5",
            "0389755879ec47cda18ee296b5e7110e",
            "f185591104ad406eb268266c4bf7086f",
            "88ba7afe43bb4041baa1238348364ee3",
            "1ec495f43e3e4aa998dcdcbbe7c0e0f6",
            "f80868e5674a496aa629b79b9aa36c41",
            "2cfb31aa591c42a2a87f4586e0884adb",
            "375bb7e02a1e452cb045a69c680bad70",
            "f3a921671ec7468790ad214a2f25ea94",
            "57be6f45a5914be88a95c908184a3998",
            "0081a96c34f649b495cd85fb50801db2",
            "6d1e6c03add1493494cc6ae04d97bf72",
            "ce645d64ff2646cab64e6ab2dd24770f",
            "1c34acef6cc74e998336acea2614b947",
            "a29a33af255f41b781407a78569d6a88",
            "953bb175c0be41c08548e3378dfcb026",
            "3e3cf2a90b2e44569b4ad17fc74ee8fe",
            "0d1954accc424b3daac072b1bced8689",
            "99d7daa32c464fa9a3fa1f988d2768be",
            "18a9851a0206407986780151cd389a70",
            "bf990b5d8b664f1d98726fe6c8b36908",
            "f04b6098e6a94a0db2e6b08acaa28978",
            "e9017d5d6e7b4845931dfb69ff097e03",
            "56d036e253b943f194d9e45079888277",
            "210e5c512e3e41b3991036689c5ed997",
            "6e1c16b5db8340739a046e676938238b",
            "05c1cce53c3846c2ba3bbcb34919e354",
            "08eedeed73074e71ab778009b9c6f09a",
            "f7bb7864f6844162abd0c8bcbf391083",
            "fa050905a76d4bf0991c4129933c5c5a",
            "772cf9837117474a84e9ce186f3a0325",
            "9728c5debd0645e38fd03e9503fdb87e",
            "96561d6cc73c42ebb1af6fbde68882fd",
            "c492235d92e142f0ba2416b4834490ae",
            "e268a19102394ff5ae37e5e5efbb1ab5",
            "99b78a785e28407bb2c61827124f7308",
            "0f82cf73c19f40f7aed404a9caa8763d",
            "d875095c55c24e9590b5ae2974b06344",
            "29149e6b498648bda7258fc3dae6c57a",
            "776ecc30cd7d41f684f23ac94c237d9f",
            "0b74e829b84c4eaaa98e870c65bc407f",
            "2095173a7b714c729d2c1bf2ea89af51",
            "8c742e69e86b41c7befbf9430663a972",
            "8ecf869c042648d79b1da17076226d74",
            "a0558e518d57461ca060d5e0cc4faa9a",
            "3756426caea34415b9a4daf31892583c",
            "77dbef62cc4143c396a99f35e03ff410",
            "1fb4684c7aaf4591af83fd34d23c6ff6",
            "615dff13163a47cabb47c06d689da691",
            "f07b253a915240f39286cbe359f01dc9",
            "c43dbb67278247338d55ca5d72ac590a",
            "e0cc123a8bea44d0b77e1f867963543d",
            "19a75367f05349f0b8e35dff3ae311a6",
            "738b658d55aa4b04a2bcd656515ad561",
            "98e28e627b284f0b9f899b65caf09996",
            "01e21cf8018a436591e5fb38e9e0a279",
            "73e6c82090004be590e934a7aa183a6e",
            "53f983b370234fdbbc064a380424b1b9",
            "92c5b021fd86411e82a603cf3ec83c03",
            "da4d2a310200434f842be403320d2b94",
            "12d2617c3e784fe1a49e75e360952de8",
            "6c27e1f50dee41cea200d1c9823c565f",
            "13e9669dbe914782b06d3d4a44cff801",
            "27d7370ab04e4af08aaab5e6521b13d0",
            "04798304e36c47838d5abc169ba6b29d",
            "e122c9836a1e4dcb9e8ecf0aceba17d5",
            "ca069e37613e46e18922ed675a39a11c",
            "cbe57bdc192c45bf9d070873b010d0de",
            "932145f612bf465fbab1c392c3b16d08",
            "6b08255a931846d1a8a8aff2136c8138",
            "bf287724007640488697c0e4a642d8cb",
            "fb536072c2db47b9a2fff9bab717ed1f",
            "d87dc2db1dde4dc7b3a38294e1f68f15",
            "995296b22f1a4ba58464692db0f4932a",
            "acc3537a8c1a46c6baef9453edb547da",
            "f4d86688063a40e192d89a5e4167ea74",
            "fe8afc3bd30843b1bbae59459fa7c99c",
            "85c517520dbb48289dd708aa216c35b3",
            "a00b29a040614878837b5e2601b76c18",
            "cbcd3685a8d44e96aac4d29a83fc7533",
            "4b7b5880d534497fb3625ee30e65adaa",
            "fa67a11bde8e485fb6b301b480c69931",
            "a96fd8357af245c4b7dcb39f3133d4e9",
            "3889ae900a9c4b6998c94e15fa3dffa6",
            "965d2c27d4a34635a9eca1f578e2b6d2",
            "151203f4576e43e489d25433da889eb7",
            "c45a164706da49f49d6f9fc0328e802a",
            "24dcbe808fc5463ab27461a4f6217f11",
            "f39dd5b6039545c5a6d32c9ce9de1ef2",
            "5b72dd6651cd4a8da20026dc29ab4f01",
            "3a2e94f739424b05808b83ee1e874b48",
            "e005171a9ad74e098d902380b11a0130",
            "89a21b68fb4b490ea4e6ef41130af8e8",
            "8b2939c81bab46338fca2efc39112486",
            "a966eda3e3f34d61b2a87d1bfe6c3570",
            "f120e97e6f594a23834c8918193de7c2",
            "a03584bd8d594558bab869652d999778",
            "4fc027f2f87d472992c4163bf7bc81cd",
            "3e7fc8908fa74a5eb8ff6bc5c60aa1a0",
            "f5c82328be7645b08ef113c2009ed0de",
            "735d0a3a122d4030962059832efe21d2",
            "f656d06530de4019be15cd9543a810ef",
            "9e354c5da75f4c0eaf36a95ee0df888a",
            "6da4efaa0df44f12a4ce8fb9085cfd00",
            "272d310f717d4c74b01afdcdb34baeae",
            "08a446a263ef4fcc83f6db0c6cf0774e",
            "c8b07d379b2d47a78f887e4f27440b8b",
            "21091199862349e09d21385fe22dbed8",
            "2c0228a8f851431a903a491531b78761",
            "d43c438fe1d34ca492de83ab03ac2d36",
            "80235ea7fe504f75ac19366d603a3dcf",
            "a0fc3d80fc424be88f01ed2c98ab5f37",
            "c3231309a7214db5a63f3fefb88d8f90",
            "a21bc46e68db481b98d75fe1774e5c7e",
            "fa99a76b903a456a9acfec36edff9983",
            "d485f783345e4777be69f5cbcad373f5",
            "ec4165638c3048b8b5183cf1dab9e799",
            "1ff03974ec694dc38ef0aaee076ea0ad",
            "b2852747f8f54e3c9b1b5dfcdc77e9d4",
            "96cb7a4a6acc4dc8946ff60978226147",
            "10b6fffa2514478aaf1446ebbc8f9653",
            "b9ddd006ba6c42d4808c04a9cced8c56",
            "a48cbe36d8f643f8aab8c6583061f66d",
            "169011623d914cd9be00fa452530b390",
            "637eea204d2c42f8bdd98acf77b2d32a",
            "39f6570d80104afeb3a0a976c4ac0cdd",
            "423e511ae6e247d098ec96fd0baaf9c1",
            "db9e05531eab4c55826145026073f91d",
            "e4601874bb814cb9b7ce5311bac57123",
            "096828f0d71d4d35a42aee52a288c8f6",
            "591e2f9de6ea433f8b83d133ce36d96e",
            "d7c25c2b14de4eebaac3e87ba8e8c187",
            "2620eb4d3ecd4ea192ac1c2d2d5c7251",
            "028ee89d35474e729b2297c33a9936c5",
            "314887c0caae44808fabd69c15a0c548",
            "15277d64696945ae8c400bf9fe8d2d6f",
            "8f5f602259804e81b496526859e4ec4d",
            "861bc161408a4acaa3284d398d006d22",
            "7545840ecd3e453b91ac9c635e08d30c",
            "c509d5a2e9d3423fa43b366195081588",
            "7f9506db72834af386e6e253b34504d4",
            "4275b9f655a44465b8500cb4662f344b",
            "b1d465bf24504ae3939a941a46d27b71",
            "76a15c3ccfb14c2691f1f6b6ce92dd61",
            "3130db01a58549899fb201c600637d82",
            "4206134c168e45f28fb7b8b2137cddee",
            "23b5e5155c7e4d47bece7cc112a7578c",
            "eee3d8dc2f484faeacce87604811f8da",
            "84d494522e434344a5e54b82a7acb76d",
            "02dbc4a4bcc24d71bfe420c37cb9496f",
            "cd1a23a3838d4d0a82411eb257bd68ae",
            "19cd3dbdbf6049ad82d57fb80a310088",
            "8fc8131fa3cc4bdda63ecab6139eab0c",
            "ecb45d0789994d7e9299ef67d2de2282",
            "e371e26341794cdaae17a383e7e3791d",
            "5dfca558acdd439b93d939cf23211432",
            "243d7e42e5204e77b895441fa0b9b9e4",
            "caaca823ce73444b942581c334759e33",
            "5b45ff4f94754142b1c78b8de13ea917",
            "d037b118d9644cd2be4954a28e58a721",
            "7ef33d297d754e60b8834c6c0db7fb2e",
            "c282b37b8710457a924b91e61ccdb516",
            "3c4690073e93445ca08b9e284d6f6db4",
            "eff9db04390840ec8b63a0e575626d01",
            "dfc5ab2b833d458587ecef6bd90eae70",
            "999e633a92944e05b80eb796f30671bf",
            "0f76f537f62345aca306fa32698d90b7",
            "d263a66492e94f309b58e8cf2da9fc2f",
            "62e9b6e355104fcc9303921f5446d9b3",
            "ddee37193f394d7ea31ba54c0a63ff78",
            "eb1680643ced408095a6b22559aebeb1",
            "2963bdcc374a4ababb5216ae54d95083",
            "9aedadaf631b43d9ae93e574d629ee61",
            "3205205d7af94eacbe2d123f68b912d5",
            "fe2d1c7648294dab9ed225f02c28b1e1",
            "84d0cb551abf44819fd0bb7546f704f9",
            "ca4e5ac0a0834efc8784e7fa0f962e49",
            "e16ee13ebaa64c81bd07ae1658e795ec",
            "4721a830bd284dcfbe1325870ad09860",
            "574a22f7b5804dd19952e6430cea03e2",
            "d8c41a9e9d2344198d49e5a4e6ac19c5",
            "6e67ebc2bd4040f083f232a55bf63507",
            "7aab6e8931f3452fa9a39d4421fcd72a",
            "4c9a0d20a8724b7c9e53b242525fb943",
            "0823ef3b31a14b889aed4758a301f07c",
            "235e4e5c33bf4d6899d6167be3734013",
            "f70fc393104d41febcb19556e62bfd08",
            "b3f6a3b9e45d406c96038beca406be55",
            "4d00f071bfb9414a8b567dcc533b1be8",
            "8787167bd00c414a870bbd4bde990413",
            "b42401bb160543d0abe57ffa1c0c868e",
            "02d1047236504ee9b4fe1e6fbcdfe29f",
            "954480bca65d46b291a8d519dc330c54",
            "b1eae3a3541b47258f002b81b1ab5a1a",
            "2050ff67b98f4530804266b1d57dc2af",
            "a51e7fcc389c48d9a35e894561d2f7c2",
            "c67ea1380f9b4e1d93c00884f6728bde",
            "bee8bad103094528ad29e7ceec280a2f",
            "854adf0696a14ce3b722c1fc5a7b5493",
            "364e9ef910f547d9b29208e732b6650e",
            "15b4120cd57748048ddeda46cc0d7a87",
            "b24bee823bed4b43b91e43998a97b665",
            "b92a71adf3704db584d87d8f1ed1a519",
            "9be4213918304bc299377ec95a0a7bb4",
            "460385ae78bb4c98a369ffad506e4416",
            "da915dcb37b14129a32536dd16dea195",
            "1cabd7acd04b4e90a9cedaaa7882df53",
            "4b1acdbd1bca4eff8014c00c9105ccea",
            "f904846b954b4440ac1458f48b7041bc",
            "a0b5abae03434b7c89e309cc3b8ea424",
            "271aeb3b6be947b7813fdc72ad76e0d7",
            "621219e956c242b694380655b424ff2d",
            "b459edfed80942da9c87e7b83ebc8cb1",
            "0fac9154e145423e85fc6c7972a2a761",
            "3bb4c3137f4c423e859699bceef76b08",
            "34827f3e7d6b4110b0dc00f5d308623d",
            "40519260be484b338afe856b854ca332",
            "9a45089a3b1f4883822bc262cd2e3e03",
            "801e9059776e4d29ba804761164e5232",
            "785114f8ad1e429683b13389074cc733",
            "64bb4f6ae7b34ffe9b621f92a6b360f4",
            "82c8e665b94a4aad9d28f0f03c568c90",
            "347988bdcd224f1dbd3ccc1dede74726",
            "94ff484c9db74e5fb137a087006d8b44",
            "070fb1ee037f4d7bb65dcf19e53a4c68",
            "16601b0b6da94797b20ffa3b3bb508c1",
            "9439cd720b874235bb932efd5bf48ede",
            "550a169673614635bf3e69bb6409f782",
            "84065afe11d544c0b0ed67ad89a35adf",
            "48d3bc750e724142a4112552aa5b2c55",
            "50a4007b4d924fafa9c284f5702b568b",
            "3f252b76ad6040c8bdec9de319551625",
            "54048da00884440fb83ab5613224cfac",
            "3647201b113c4c39adcda9a404dd17a3",
            "832753d14e9e49acbcb6d30f7c41ac92",
            "b703bd51708141cdb597020148976178",
            "ff63e7feb2534c5a83634ede58303ff4",
            "e90ba6b6b0bb4bb4a744d033e28243d6",
            "5f8eb059baef4a07b1b7bca2818dc28f",
            "828b5844e2cc49cb9cc53e07f51277d0",
            "55d655ecc0d94b07a466813a494304a7",
            "8d84f17b4a8b4e64b27d8ef27fc8e798",
            "f74287affc1e4534a723b2165397795b",
            "968e59d7c2564f65be5c1edc8c8675ce",
            "48bbdf93a4d244f7bf81dc69114253d8",
            "2366dd9569ec488d81332386f26a3e4a",
            "3de5c3adb9334a78be88976369beb65b",
            "e75ad92ac23f4a73b752b71e9e1ca85c",
            "0ccad76f9e0c4d12853946687b3d392f",
            "b08dc69c97154083a30a3ffc2fa8b796",
            "6c4e0c5770bb4fbf9906833bfa120060",
            "2843ffadc58746f48041b82a51ba10b0",
            "c40dd13e6f3a429ead0dfbcfa2e01c98",
            "31611417e0e04d05819629c358b1e9a0",
            "041c20c7c9c84bd580d40f50fc0fd705",
            "2802a2d7c014425a8b1ed1bafd59c7f2",
            "0c13a32267f047199967c1411b0ca23e",
            "52e92f4ba55a48728a0788266b54e690",
            "16d27b7775814bc88b74a0234037ce27",
            "089839d37a604794941a4cc1f30bfa82",
            "1ba48a787bf146c08174d95a0a9716af",
            "166a53a7c2bd463380a4da36b403f8d8",
            "eac0c2962bab4dc9a151e81852bc9f88",
            "92043c5aecfa49649195f7fe662449b4",
            "eddd38a6974f4e5db2631e36fdc857c7",
            "63bbebe75b4a4d20b44f070a7af06a65",
            "6b5540d0d5204c5b807a3f5a3b1a7ce2",
            "15d7bb5db7734ae3b4d1ab657a31e6bd",
            "6cd6dfcf23bc4b5cb2c275579a3e159f",
            "75569fce8fde45f0ba9245ff49841458",
            "63e92954bb48401abed5c3fa5c3f4f32",
            "b43eca09551146aeafc1f96af67faea1",
            "ec1e595c0b0743b69f0c525ca7e02871",
            "28b5a3df8020452098bd9b459984aa09",
            "6c5b0d25aad34843a4ec90031f60ec85",
            "455dcf9536b4444391bf7d2ceacd5352",
            "18f9522019734a348ad759fc501f895c",
            "e6b6102ee60d4d1d83bff6314bebf8e5",
            "478bfb5945c54f858945f2da2620a86c",
            "efebdeb25ac447c9ab81c76e3890f034",
            "5fa3980f4f9349d59dfe892a40eb2cb0",
            "5276c4cc9fa54f4aa73cf1586e4fb988",
            "9752a9126f314a92b94ba231330512e1",
            "95c794c46a9647c2bddee3877e9f2693",
            "1a17ab3cfb9d454aa3d24b68d3edee59",
            "7546ebc5fb64404bbe5e834537778483",
            "f80e3708d5f74baea94bb460dadc958d",
            "122da3fd43174eecb158ba5f0e658c4e",
            "7caa04579bfc4b1a99bbb4743411a6c2",
            "a581a5ece6734556bdce9cadebc85671",
            "879246633e504f18ba567adf3127aa8c",
            "58c925400441440086a5ba6176942d9f",
            "ae13558e2582456b93069df9bbd9fb27",
            "167fc2df0ae84cb2845e810b10b5ec81",
            "7a3ec305930746be8dfac6cb1f0ffc50",
            "c9c216201ef64476a0ed958c05e22573",
            "deaf4ef6ea2246f5ae21f1ec2183a48c",
            "0544013043854cb5928419399e1c4a9d",
            "e026d513db21409c8f2c9702550a3134",
            "41d6aa7492b34cbbacd03430fe48f7e6",
            "cddd46148f014b10b836be85e5840ead",
            "d6826b80deed43ec868d8c93ef9edef2",
            "398c95da331c41879b8e873f12a4a764",
            "7be16a50103c4faa88d8aa8157e6c38a",
            "d14d633b1df74e60a292e22d532b2657",
            "6f0e4d8eae7340bfab106fb9de608477",
            "bc5da5dcfe334db0a580ac34568c4cd0",
            "3d74c22cdf2b4076b103c4413603e936",
            "8eb13d8a93a348c0bb648c27ee64c981",
            "8a423cf54a674b33bdd7d509c25dae08",
            "d406f386efba40078b68144303390248",
            "0e5de022457547eb945436c5a6d77dea",
            "dd462dd134dc4ec4ad8742eda4390388",
            "cd8eeffbf67a4dba98f05e7cae05e746",
            "65b396b9c9ee4cd1a582d01ee591ab52",
            "f57f7e892eea45bd987d8190cf4cf337",
            "6b1c89ae4c144e0ba6ba41c818774319",
            "872de3d78f0e42b48d5ebf400ff3b555",
            "8be1cd4c771e4339a55ba76038ff4303",
            "4e8d48826e8e40509b4351806b2d4f67",
            "81f91e9cafa1459781ed3c1d716cf684",
            "942aef8568f44711835a97d649bd2494",
            "a55e76daf3c3443db3d0e9e166d6a444",
            "c3a1703d1f3b4c98888215880fa1d322",
            "5cb0a21822114fbabf0bb3aac0386dd1",
            "30c175c32ef24a189bf93d9ab6ec0edc",
            "0f0876e51c7d467085519d405491f67a",
            "695b1cb899624bf79503e949e345802b",
            "6a4b5e277bde461981546aea0f58d48a",
            "f8015abf265e4c769c45b36e7c064d71",
            "8b089620dbc747aba7bf2bd81ce44485",
            "cfd1f5fda49849ba9015eee0ef7ddf77",
            "2ea3465850584997b9b332591e4fa6c8",
            "de98e57515ef46e59d697c3aa59e1301",
            "b45cf61916e8451ba57c51db84d7d166",
            "e3505b51ecdf4baf9d6fa9d4ed050cdf",
            "0bdfed8c459d451baaddc5cfd2c9a970",
            "8f1f1b97f75d4cc7b8a32d02d64f83d2",
            "86e2d0500a3c43ccb5155dea284e9f78",
            "ec6f1123991448aab9aa9b7eddb98c03",
            "73abc4a075f743e29cba7dd9a09eb63f",
            "439a34ea5f2f4747ae3b22446e2010b8",
            "d317544f80644726a99e316ca3d8899a",
            "ff9247f1cb2442af854b690fa2f79ffd",
            "bbbf89d9454f4d598561effd9e3c2c96",
            "383a92cf28fc42178c2f4d52c09ce4de",
            "317c856cf33344258b1fcf4bddce4df2",
            "e4b30d8a6e284e57a34862dd8df2a2e6",
            "c59d2969e45d47d08cb7f14527f13380",
            "aa737f1a35054a779207c9ba07a77633",
            "5c556d3c3e344121b9d726e05afd6224",
            "a86370b02559470d9d4482f64c1cbbc9",
            "97b25b4006fe43489e83a8b67246a58c",
            "8423ad407dbe49b7b8fde72ba4c4eca1",
            "ae62c637b3704257806dedc6ef91d75a",
            "9a4ecfa73f174719b5685cc21e4594a1",
            "58cab4837a184b6e9c96c8d08f4f9d59",
            "7bb59bb53ede428289feb340e8ffa84f",
            "11295f4d2228470abf603c3ac2bf2cb3",
            "ea303d578f3c45a09703b62dc0f2e40e",
            "f39331491da442378aa0263902030fe5",
            "1e8973399d0e46bdb66c21d5c5e457a6",
            "1b6478da20644ebb8e0eeef5f1492a85",
            "e64c98ca222446d0bf4d37a3951edac8",
            "e3a9de0aff3d4baf82506911e36c376d",
            "9ee0c0e237f14900bd8d3950b1c26f0b",
            "0c21afbe872b45708296cdb1a73feb57",
            "c6908b29398149098f71f64d1f7b6c41",
            "48b6018618794a009a397838f157b16d",
            "b1799bf3e0a540bc91361ca1d7eee22c",
            "184e37179d03448080fa53a7925345a5",
            "f8f3a00198354e8c8ba27978b9c84d76",
            "67a3200665ec491b9ae33fee98c43722",
            "0f689213e3d847928a51fe3c678cc920",
            "352b8d4577ce48d69209305347b99476",
            "28df820501674b12b835660945b4c686",
            "0c832d2b861147f1824cb91fb1fff07e",
            "0602064e73184ba08e0d45e791813594",
            "75adcb194baf47b08eb01d94f1a26099",
            "227a2614e9304629863b20dd6c265ba4",
            "1317805f6e874ea2bbd23a46a924ca56",
            "963e16bb299c426d9f6c4a5cc31bd05b",
            "bb3601e7589f4d04a8df3c1b6edfb866",
            "96f23ac19d0647aab0d83ebb5f47a8ca",
            "c7b755f4c04c472c8cbb56618eaad576",
            "88c3b33414d945c28c324a6379bd1621",
            "cbe1af8ebf4246b1b520fa14013fc007",
            "f80c1493ac604255a7215d5f6af7320c",
            "060d1f29528f4fb5b6139cb28e2ac450",
            "fd018158e20f4a77907c9bb671ef4344",
            "47e57541a428474cb48e1c6e039db918",
            "3b242c241b3d4822a6ae5a07fafa9d13",
            "b065f8034d724b23948a585525483987",
            "3c2ec313ac214782ab98626add0ac9fb",
            "dfdb78bb020746559f0552cbf8fb5640",
            "cdfe5b2037e740f2a3139b829175e6b0",
            "386c692fb10e4d03877288e26237b6e3",
            "b6409a46d9514e5ca7c8ad53ed396e53",
            "460cf3602fdd4a18afc908646ab927f4",
            "df449c62cbdb44ba934e1c358c3af8a5",
            "559abe6ada79440592c0e66f79b10a45",
            "e0b71a6eb0f049a0a2329ad73c7432d3",
            "3c49d2ef4411470fa4ec78521db0c96c",
            "ef28f9d2b9c74ea9b04d9e59e4344769",
            "2dab9f03cd604a9cbed04ef669c42597",
            "172dc414d9be4530a5b83d66230d8f0a",
            "7fb3827e681d4bc78d81ca4fb20eda0a",
            "d90ec34e5da344aca9c9814de6c1f319",
            "5ae17ba065a040b6a8160e5f75daa873",
            "bd73b205bcda401298387d71210d82f0",
            "b4514db7c887470f8d3d516e7b861aae",
            "3557cb1b6db44a98bcd52c6ecc3ecd08",
            "dab2352397d5480cb49b651daeccf129",
            "7b512f91a3e64a97a05e676b8ce97393",
            "fd98d825665949f0aac98e9586249574",
            "3e9ddb20fa71477f95e1e96a03a69250",
            "b53dd0f1dbff41eea3bb0cedd2e0b298",
            "99092869f75541c58c27605f3551bfb2",
            "025c2e3f92f44be7b6dd489530b25de2",
            "d59e086bb2f64c02ad0672d5c593089f",
            "80fdb9e3d6bf446196c3d542a9f0c355",
            "db582e48223c44bf845e19680964b6e6",
            "2c7a9d4d8c7e4e989810c84d383dc4d5",
            "d4b36bd644d14647b566455828736b49",
            "d0ae20090d164179b47cb634498bfe62",
            "0adddf88cf1a46a196fe96a90425bceb",
            "8618be31198c4c4fae120b49b2db6b44",
            "1207c790692c439882d79f9c02a19e5f",
            "66cc0570571146968e59d6697eb42418",
            "dd15fe1260fa4a91862490ed9e614e12",
            "18f0e69598b64d3cb04ba08fc8c8505d",
            "2f755911e35744debd212ed01950d638",
            "8990f4afe60146e7bf6414e973304237",
            "10a0bf0193ca408989dafd9bb058d307",
            "7be687a2e31c410792637bd1f838e99c",
            "0ff3ae40c0d4415cb7cb25b481578f92",
            "a07b973f2c534b218d5299b9081d4847",
            "306d667b4fbd4cf7a0d9a0405a480e21",
            "e91ad4bd03844552ab75f5d5feb7f6e3",
            "711d33e15ef54f19a2b7e39696756851",
            "c19d255ae461499ba2a7406db5e2f45e",
            "c2570f0091a645a2ab7bd35dad666baa",
            "e1e17b5fff904a118ef96e1aadccec9c",
            "dc2ad8c893fc4d5e8d3e23237f289fd8",
            "27d12116ffa24a2c82b2dd8aa1544a22",
            "acc095a102c744adb98c48e00cd8056a",
            "3ab3f943f6914e62994249dc73e52f1d",
            "88ebb5da9b3d4b89a1bf5fb81413c5cb",
            "3cce51345f924049bb046bb65288b338",
            "a5e97ffbebe04925aeeb49d39d5cea94",
            "ff17dbf2a9d64237a74bfa705b019b9f",
            "723a0caaff004c879a2b908f16b1853e",
            "2980f9a7d23c46189fa1411207739459",
            "4460ddc84ef141ec8299d7b9b48a88e3",
            "fcbb0b8699784f6cb99a174397d06732",
            "109e69254739409094e9fb2e399ce512",
            "0bc167e5569748a48d51dec568b9545f",
            "7fb5273861534070bd26d4bb7f5ae9c9",
            "24b10b16a72343e19b627afc75abe3c9",
            "8166177fa7e4475993e220a0ec9c50cc",
            "78d9e566b9f54ecd94777937f10b4890",
            "83e0f2a0fcb44a5b8b30d65bebeccf0d",
            "805790003d6b4c88876217cc533af516",
            "305f487ac0884119a3eb3b107f8604c2",
            "601995ccc99b4d4791b69e8dd3a13df1",
            "6b8e389e7e684423b8a94405e60773b8",
            "31bf4c4eb408456a8af86c2b911f819a",
            "e903f9fe583a477fb807f96df90e71e0",
            "aed6805211a04e01830687617a62e3f7",
            "24a865da19a2467fbb0fd40145dd48be",
            "757481b7ca944bc0895b24c9536ade56",
            "4709e89997514b18af6a876bf2104fee",
            "ec352b9a8eb04a40b91a59a4fafe2fa5",
            "92336586d8b346b3aecfb16a7d7fc7c6",
            "ce9dd6bbebf64bf4b0eec7340dc4dcd7",
            "b71e42ee2f7844f0aadac5e19e7f6035",
            "69280613ff98414d88a76cc37203bd01",
            "ba6014262ec048eebe85636aab2fa003",
            "781f07fae9e34d8586a4d188cef645a6",
            "ae5376c945e34840b8cbb791726352dd",
            "8fd604b8e86b4dd6af27039e413f01a2",
            "ca21d40df84e4502a014d14251556702",
            "cfb10e56fabe4ae99f0fbc1e6c9332ca",
            "b858aa341b8743c6a84cb889d8d0a84a",
            "b052522a7a574441bc467eca1489cb79",
            "538b3b2ba9d140229be81193c7290289",
            "99fbf35a63714e9ba3a3246c50e60f22",
            "45b33c82aecc4dbb808acf2d3d66c683",
            "5c7522d9f5a24cc880d6dd0ed4c76938",
            "eef4f84f7036453694a597e2d741cb32",
            "ada490241b944856a7f383483a6ea53f",
            "1609c22c96bb4969a0e6457eb6a51cce",
            "6d647e86cf0a4494b78252b92fe3a4fc",
            "b276ccbbd62c4cfaa423d55a7d8c99b1",
            "c6527d1c1b0a497892de404dea6d7a55",
            "a2e7e6eb18554bcf9a8c6f6cee290402",
            "e4cab2edd1034838beaa9a41ea7ae7d5",
            "523bec4d04ad40a0849812a505f73af3",
            "0cdfd9cd4aa74cc3b969bb5973bae0ee",
            "608fbb8a502346d49deb21ca2673c71e",
            "8ce8ab4fec974cde9d7896330fa24e11",
            "360b0e8d48e34e3ab94ada202070dd1b",
            "150a4345c5ea4fd9b53043a2f48f43e7",
            "d6566954cd554307ad3d3ba3119ff628",
            "71fab81d95db4e8bac2364a25e39ed9a",
            "f442081872c1449684084b1cd14edb5e",
            "23941efe688a401488936e564d8f014d",
            "2e9a2dff2d804b2784b4bcf57ce5538a",
            "d8e9dee29b1a46d3a4b4e9e50d975006",
            "2029e81dfaed44cdbff84b64c9e9cbe9",
            "6169f695e18a454fa7330b77719a7fe0",
            "730459aa4c034250a9deba239f3216f6",
            "b0e0c29abae34cd6aad3cdaeb782ab3a",
            "4297a52a40134f3c922126db97640a04",
            "b15b8f8eb6e542a3a9354b364f8a5ccf",
            "fbad6e8470dc48578e85b9b8d1dee95e",
            "b31bcf4f1ba94c01b7ef77cb078986b9",
            "cf9a4fbe0cb24b7fb2a202f0c47b63d4",
            "c39581a6a86e4d4c9da032cf5ce2b535",
            "2cd861c4d219478a875edb1a123828ee",
            "79ad86bebfb44fe5b61125e5f422bffe",
            "24da6d3909814a97b34d2ee9424dcb7d",
            "f99c9fec503e4d22b94c1c2690339fd7",
            "5b8625e4df0247a991e87e1008ee77de",
            "2c5bb60e0bba41f889a40684a9f5ea80",
            "f5778ce89aa44436ab68d350b50445a9",
            "daa7c9ae13194c5491a28552c7cb7c7e",
            "63c3e1dd498a4946940f2f8ae4048150",
            "c6ab9d66a44048b888f4975fbeb03089",
            "f1a4015aafbe4bbc881dc2e3c8fcaba7",
            "d1c96bf1f2e1475493b9f719a57a8138",
            "fdc5c01db6cc442da7dcbecc5caf2ad9",
            "fceef30d47c34a17b9cf9b9e2b65557e",
            "e103e96f03ed412089ae461c54f848e5",
            "83bcbfc8af5b4181b8a6e19076b6d8dc",
            "63cee425a908401d8f9396ee8a57c761",
            "4f9cf1573b694b639817fe2f4e0f9bf5",
            "1aacc949075a41718af5cdf3bdb4b7a1",
            "a5b108f2ae5d4563bc00a2e918c584be",
            "e9c991643e34462cac1df72e30df0aea",
            "55a35a6940e14d9b909b5640f394da29",
            "d8608c4b2dd84685af18b957353b7a8c",
            "9a4402e62b6e4d74963cfef9d105fe23",
            "05124538166c47d6aee4d597df79e155",
            "688900319b544eecb23eb06a7ba44b6b",
            "f31e99efe8d44cdb9a93c7d14d17e074",
            "3c77bd12c2194718a7dbefea7ebe3e1c",
            "17d0d03178cb485680dd8f73feafc76b",
            "b9d5ab2c97384be286a94fc61d5812e1",
            "69ddabc180414f2781b87ea885c1d694",
            "ec41dd5ee56741b9b2f4f26b990c2707",
            "a4120428f8cb4a07b8238789d76a41b4",
            "3c7c72ad409a4fcc9cd0ac11b7dd1943",
            "b70c197aaeb9462494c2b9fec6b88e65",
            "d9df04f6206546fa928b623c2562e28a",
            "aef052e30a0f4051b66baa6300c783b9",
            "446f935aa19f4e61b182e5c2ded65faf",
            "acdcf6155bc143119dbd9c8426c9c60c",
            "d25c74a596644bf88d45eba815191bf8",
            "a4fbbe1e4b574636b11a90eabc7e0c7c",
            "b7f4570ef1214498b4da3cb59f28da9a",
            "475e70ff3f79497b939ffcda605f4f4f",
            "97d0e8302a364787b9a37721bc3eda58",
            "e0c4cc5a78314162956728c0d4219520",
            "c9d4daa4f9884adc96911f98cab967fa",
            "aa077e766d484148a2e55b8ca3ce9562",
            "08ce3ee3e60a410a98e48472c86225d1",
            "922c2a7cc7a04e0e9783be667e3a10c5",
            "937e25945af84723807cab944dc34f1e",
            "8445918950214391a3647bb46192b1c1",
            "e2357e502aec4d4e962ed8ae6f49fbf6",
            "7c6fa22b622a4397ba4a315d2fe45e84",
            "efe54d7799264147b775784c022e4771",
            "7681381fd1fc4eb69d0ea945636e69ae",
            "4d6a4abaa7e542bbb01539460a0bcb99",
            "e6b8fbf286314dde830a494d03da73c7",
            "c7fedbca237f4804bcee568e3cd8e20e",
            "add3b09fdf4c4d108a52dd190caa677a",
            "aa7be409ce0d4492bc5a00cdb64282f2",
            "7a03daea6fd94a7cb187192314fcaac5",
            "d349637234264d3bbd0ed2bc419e8f14",
            "da5a723ee31b400c9880a201cb3535b7",
            "8da3e78095744e10a7ddbead24231e16",
            "59099b852e6d465b83f5bd13f1ba100e",
            "3ef0966858844a17b2872a495ce3a96d",
            "3f2c2d87f1ac47bfac75a1a2105743d9",
            "3cae9dbbd7494be196ab5856b9326873",
            "58866d286a4844be9b0e78a0b2af5b50",
            "4cbc0757f68240f1807c678b7d0b0fdf",
            "b23259d1ade04747b973fc7c03b2d95a",
            "cafa5e0477044994bf0e192690b60694",
            "9249307887034a60a6e358a5384009f0",
            "9f3f17b282f2489e8046e5cd8177c0fb",
            "f36ce0949b024cda989ef90d4ea9acbb",
            "6180bb5fcfde4ee3bb836a224f11a9b7",
            "dd4b5a82dbe34d81b6eaefe4858095d8",
            "2cf37c807d1c4ca8994a73ef1f1fbe09",
            "1fae1e6fd39445e98fdb481a99182483",
            "c4e6b4bf9f214168bd294a1c632c30ce",
            "839e7c3d2eb542b4a295f8ec58b1efed",
            "968c1611ce0842ff8d3cd9c29b57f9ff",
            "04b7863b82c3477a972bbfb522ed1486",
            "8fde7b6dd71e4392880b811181e6ecaa",
            "076ec03ab0ed4a32a38b0b15090e53b3",
            "7bef5c9ac0c04aa5b5f8657603172f4c",
            "535c2d49e00b4fd0bd9e03ffbcc0a428",
            "2f80495af7eb44448be80dbc1da1e29e",
            "de6dfb1c2acb454385d6440a8f9b8fe1",
            "39ec76db8fdd4f41b7931cc362eedc12",
            "4aad99f17d884f1fa883bd3b83ad5365",
            "de7e9c79042e48aaa3a6e299e5521b35",
            "8c6228db9e8c487ba1a7f3fa98742e25",
            "ca380cfc19a7418db4a20a29c496657e",
            "aa23f44883c940e3b865afad6c5e7b9a",
            "5558e90f53c44de3b16eb54799a995ae",
            "9efeb1c5bda44ef98de49b9d32efa4ef",
            "22d9775265934600978796bf0268a796",
            "7d6b583000314cb984a14e01aea84202",
            "a59966c512d24aedba8b06f766e93f73",
            "022d3d6d22de4c698b5db60fae0a4450",
            "a126f4f6a40a44f5a4c6aa12c05f16bc",
            "eb1a5e4b73694b93b0deef78989548a3",
            "9b004fa3bb7446209696988dec4e0a14",
            "dc22fefb4cfc4d75936cbed73cfe7a19",
            "2f2786183a1043c3907a913d8f566232",
            "feed39d5904f419dab65d6ce5572ffb9",
            "cfbbe01bcca941b493277352074596ed",
            "c5ced8a603da4a25b9206c2af840e6aa",
            "199046b6230f448c824c0f21d965d3cf",
            "db83c410f2d7477ab8fd8c365d5e0e89",
            "4b7d4a24aa0e4de0a5a5192e4a92e902",
            "77989d604f7d4bc5a174ad99cd755ab6",
            "7455aa5ab1094d6da3814bc80f24f5dd",
            "8b568afe5fcc4dffb3799c9b86a4d7d7",
            "5d835805cc8a410eaee8035421ee4998",
            "4bfc96d4b767475f93a5f25b13fc3377",
            "ed0751a5644a4a1d91bb746b1ba23f30",
            "7595df3ef5bb4d91855f6126e98181c9",
            "6955b88eaf1c48f48934f72eafc6e6ed",
            "5946547ff6e149e1a21ee1bbdb170ab0",
            "b300af3b6f074eb9a290a0fb3d4f876b",
            "8f70f39cc45f4a9782ecaca1e347beb2",
            "14297198527a41929aac1fa61f78f9e1",
            "abbe4dc6696444eeaa5fac5d395ce5c3",
            "777aee5f1bb9489b9ab22f0685ff7280",
            "e29c6b74fb5346f7bc93d2dcb6f26bc8",
            "688f3ff1a27a4ae58f1389aef8d94fa6",
            "cfb8bf3989bf48e7941fcda0d37e90d6",
            "327296dc7bb744de925d0c8b75a7d3de",
            "112d8d1c73c04f39b6a6a68034d8a93c",
            "ff218eaca93a4c3c91b214fcc9b45d75",
            "d00b1fac5cb4410ca82203ee81753a74",
            "04db6be996fb4da8b7964e01bde9e721",
            "9651aea581b0488fa0a86f3460ddb9f1",
            "8c88e38c9ccf48b791fe949b87fed3df",
            "e5ea04f9fa534b079bbf32d11498709b",
            "c831a7cd7316494cbd5cda6c80a7acfa",
            "a0e7bd6b4fb44db8b9b3326b6cc154b6",
            "3009f61931884c74be1e08f625275020",
            "2940769ce8764adb9c812366561db2ee",
            "e0e443b6eb054b59abb6cbeb4d5e4093",
            "6229ee88df4a4163b8ad11f4794fb598",
            "65006b3cf29646119fd3d1d8a0b9f862",
            "524ac6cbadf148a68e66454eeca1815b",
            "3806ca61af1f463eb7cf093b32a3d257",
            "72ca1f0f03d04f8ca1883df502b660f0",
            "9837aa39ae3e44e98ccedb6670a8f638",
            "815f2f5755c6469597eac4ef314b4570",
            "a2419fc155964532930888ad14c5ae97",
            "ba77cb900a434feeb1180ff62f636bcd",
            "8f9f72215dbb451f85c8411acb1aadb3",
            "4c5f4e1bf5ac4433b71b28984f23294e",
            "d22808245fee415bb897f1982dbfd966",
            "961786667da444d2935e96bed98ef7ac",
            "224e7c269bbf4eaeb712ba9ad9426dd5",
            "b34e060adc5246d28325ab1527a3bab5",
            "1f285a45096544679e39b02d89e10eda",
            "b786ba25ae5e4f969a5f58810c19528f",
            "cc6c471001fe4fc290b2372a66e52422",
            "786ec9cba92f4dcd90e20304d3c382c0",
            "9619e437a1954c58832d3c4197e84fdd",
            "fec5638310c342fdb51ab081f1f12e40",
            "3dfb63bffd064389af1b4a337b8de054",
            "8f828131ecb64fda8e041af6b3d7115f",
            "220ad974d108401298dcc4e80fc1ed09",
            "e2073f55f3fe45d38375072970a8fbb5",
            "8136af4d5e8a4814ac2a86241677a192",
            "f0ad586dd9c447669ed8b8c7dde2f486",
            "141246e92bef4c7c801f0822b8519cce",
            "8e971e4b06c44f53ab07cd24ab931d57",
            "afa80baf23d544faae688af472ee939c",
            "6eba26a32de94bca89f936c02f427000",
            "6d57f7b032de4978a5f19c3c1ced278b",
            "8118462f7e9c45afadcbe573beff86b0",
            "2402fdc80d914b219b3cd07efda0b836",
            "f5d5cfee034842dc9a045e05d6d91181",
            "7164f8251e614c6abdc2b08f16556023",
            "7e26ebe6e57c4634852f68ca2c0fc562",
            "2c3f46c50cb44e6d8b6ce1c0cb9ee9fa",
            "7bf02792caa547e1bbb4be0feb255a2f",
            "f6356c03d2cf4b0c92bfc03c077b82da",
            "56f4a3e9ac40415383c87a2bec940512",
            "5c833428ea02449f82058ed7f987d1c6",
            "587e00f9a25d44f1aacf3aaeec987e44",
            "e95040a0076e4b4195536b5d83d38c69",
            "27b2b7380c0544cf823705b474ad3d87",
            "07d6fd9defd344fd856d4d0e8bf1d9e7",
            "f1942bf0c21b4130aac012c65775ec99",
            "1f33b4252c404016917c92ef0068424a",
            "068121ef1c2f4af6aa4edac60e235ce5",
            "8eead3d759d2498c92f51f95cee2ffee",
            "1f594ba44d814c89bab4bdd04f9d9a61",
            "2747799d12604e1db2727b35e00506dd",
            "b987c4bea3c8404c869c972fb1369793",
            "ca0bb3f120ea41c7908c157359cc7abc",
            "eddd05b82a7344538121f195d81d0f82",
            "ba07027e9b4f4003a915c84a2e659079",
            "af332d0e2a34489fa3544b352de3bf96",
            "119ad7582b8e4d1c82d80be8b95ef9b0",
            "b353b32622cd4617ba1638d38886cbd8",
            "1b21c41a27154d72856f3cce957aecf4",
            "3cb691e52490448ba0a011a6ccad6a23",
            "44239d2291a346338a43b1ae1e6d04f1",
            "58b8f884baf547f78dead4bb0325cb01",
            "4448e374a13c45e4afcc1c48e3ad0b46",
            "31c07c98e8db4a55bafcd306669680a4",
            "11c41a101cb74e9897a4d82aaf11bdaf",
            "346bc497962b4d3786d61b787f0ef0d1",
            "b77d2d92c1be4c0f917e3f6ae6a405b1",
            "88cf098112d04794a7cd28548bd3d3a0",
            "ab659a13982d4833942b402454fa47a0",
            "05bac538034f431ca55b8556dc54b761",
            "49cb605cea984126907b918b25d2252a",
            "69036ac6448c49689e7f8da9b81863d1",
            "eede34d0537d42638a91ddf160e010c4",
            "67682c37799746009a2d5c52ac4918d6",
            "920525ad2652469f88962dee95212da9",
            "9ffbb6967c19479cbf54751ac0c576ef",
            "754923ed4dbe43f5b9b1356c24c4dfc4",
            "ff1a2ec1fcbd445e89f814f2fdf07c2b",
            "5ea6cdb816e24f8d8eccd9c4d3578e25",
            "eabd23569f33407fbc0b0597686758fc",
            "ccd7ef83cb1448efa11ae79ee562ce48",
            "2b689ec1a8a94efba4d25315d9e1a8e8",
            "202bcadb7ae2431d8da450696af8fec3",
            "0be2ee93b06e4a39a760aee2b8569deb",
            "0a2dd3d58c5c47509011f58200383e4d",
            "5bb150e26f4b4680aec9ff996a0bf212",
            "1d696bc5bb4449f28e93386ad01253eb",
            "260aafcfc7fa4df6a5098c0455f6739f",
            "9c874798a8454cd2a0f8c5e4a09c1e1b",
            "2d4bae175ac841e396147b929e5d265e",
            "6d0026696db74e8bb4f92410e9e34c33",
            "3e314b556b204de89c8544b957c5e71d",
            "ce5f90b09d10430da217e9ec46141ab3",
            "30c241293ee14b37a266fbfeed0c2845",
            "c58c18085ccf4f80845572342bca2cc1",
            "be6e56d4248b456bbecba6b8ac5ef77f",
            "dbd41ca3fc0e4a6d99d7037ea60bec7e",
            "0b016d1dca394e9285e0ea11f7fbae08",
            "d344f09b7cf2450688bc4782c40335a7",
            "9b9358d39fbc426cbff034e24446c913",
            "5221b6f0d6be4177aac005cdccc678bf",
            "2f9f138564c3484c9f032b37f19ab3eb",
            "7192e40f208e426f872e2356a66a7f24",
            "bd65ba7249574597abed29c9349bf138",
            "b7a12abaaeff49bdb06f5b523c15aec4",
            "322745224c254086895d22e74626f6cd",
            "c70ae589da0a4da2ae951049e16480a9",
            "a0bdd6ae03bd49718c6881142aa88b6f",
            "5dacb44f2c8b4f38aa71271dc257121b",
            "781c9b7515144bb4b7f58781ebdda91d",
            "5a374b569f61432c9c8dc7d6bfa15bc1",
            "dcaaa606b636493bbe959da4d2fa1c15",
            "4b6c218c4b614900889e04bffc205c40",
            "768e2a6756a046e0b1039ed85c2b7d3a",
            "5a37cf55a2d84f0f83170d0ab4cae282",
            "4b81070d8b5f4751ad747d174e495388",
            "0be9ab22ac1d413aacb3a5403b66524c",
            "dd01f72317ee451dbccb2a0bfe0e7a92",
            "3200b0e844a1462289fe4a901ef9899b",
            "eb4b88778597468e8fe830a0fb1c5fa4",
            "a686a0323e674935bba4eda48a8a7fe1",
            "56128ae3cb8e4d84b42473e15fd6b21d",
            "c98f9115fefd4de0ace9d579087ea310",
            "a278809b73a2440bb3c3e2f1245e53e6",
            "669dd6459dc64b41a3f12c5712943bc9",
            "abb135dbb9c64008aae3576166dcaa2c",
            "2c1376e9e28c41aaa962be00fcd9417f",
            "e9491057e98e480e89ef165474c43ab3",
            "139624ce641d495f9be9c73775260721",
            "9728d51ad08b4e2091592d79b2e3b706",
            "b69f9e098e074fee8ea149857b05c7f3",
            "92adf7a0d8ef4b8e86ef8447eaee4155",
            "a228632c7a864784925df1b693b07fd9",
            "feb1691b5271436e89d7a7081a15eb53",
            "1353380f9dcc43609f37f41dbd82f398",
            "9404c647c1894f67980fa53399aece1e",
            "9eae5136f7794091a2ee51e195495085",
            "d497f47eb97e412dbfcd2f63eb79ba79",
            "1ad7c77df97e470585625f5413b9df54",
            "61d9ce25c6e94175ad69217fe358c0f9",
            "02cad5c8117a4231b1b01dd7b5e1339f",
            "a365e39e279c42eb94fd8088a9ee65a3",
            "2aeb53d5d99241d097467c1be66ff82b",
            "4c91eb0c23fa430bb68a6889ff414bc4",
            "3488456092aa440eb59e4973798ed977",
            "0631c6bdce9a481ea671878cf144e6b4",
            "4405d067e2c943b19619702356b0c99b",
            "b37d37a1fa23461b8f2a4fdde4a83d0d",
            "b4e0f7828a1d4d499ec2e4065c08ca27",
            "18099ebc12bd4676a6d47d9db90039b4",
            "6df47b2ee09d44f59c7a1c87e01c9bde",
            "537300ab68354c848b1bc0b33a78eb0c",
            "588ab72d7cf046cfa2e048c6522bd9d9",
            "2bbe6d6e46f046f6bf126b33adf830ca",
            "bbbd02f1726e4ec1af417db037127547",
            "f3231dd726694de2be6b0a4da3d4e1b0",
            "875f2a5a79694a5f889ce3653b79d6fc",
            "879d9d07df7343c0839f3237993e5613",
            "c9590449806f4dd993fe0bf7c2679af3",
            "03d777cb34f14a2497117da59804dcf2",
            "2e0beae3d5794361aaf604881b66b076",
            "03e4503bd2084874955f6d262b07410d",
            "84bb6b7d17fe4a76a252b8698687d972",
            "184f6047302f4031a499b5535ca9e0ce",
            "ff01ed7edfd24ffcac9d52088299a3b1",
            "dc41c97da7e84deea9db732b0b92f05c",
            "a9a70fe6a1134185a9ed73b03e3b9d43",
            "ac17ce16aa82463684b2c71c1da05787",
            "95199d2192d54d0dadfa77f6ac27c962",
            "60f18545474e4dd2ab0eea8155e57e45",
            "4b5d4422236d44878a817d67f6d55550",
            "dfd3bfdfbf9a4531b9e04c4bfdeb5a40",
            "afa1633d0b2d4407927ec1ad2cd55db7",
            "42e9e292af954c8e8fd60ec534ad8ec4",
            "2c4a70e03e0a4179bf5f58c828b1288c",
            "3914b48f67ad4ed5b1a47338123eda8d",
            "c58c266031fa4dde85edd8e8d0f380aa",
            "2ad26629a57645149b1d4ea154e87510",
            "d7c6cb7dd75344568eaeb0c0cda5d92c",
            "b11e3b3925164526b61ce324e25fd40c",
            "0f77a61505b54c629e19eea2172714a9",
            "ddbc252d6e8f4c29995ff24484575c5b",
            "1cc2275afcf84be0ae17dc1f0e1e26fb",
            "e775dfdeab074a65aa5c19988caf1644",
            "92f079acf81d4323809a8b05aff47d8b",
            "23b82a6e221f4f2f891471c2f09d9aa2",
            "ec3eecb6fca648d19bf81cfed162f1ee",
            "c104d0456af0490ea8fd045f597c2266",
            "78aa04e0e09b451389a10924a8123ed6",
            "6048853deb7647b6b74753cefad53804",
            "d0bf6d8818bb450bab9e426d5fdefb90",
            "eba3330c965b4fc4a1e1effb5b9cc9e0",
            "af1924099e3f4823aa2b344e46d45735",
            "38370a3401534394b6eed4e11c38e8c7",
            "919513e6034841e7bf9012075e600e69",
            "913052d04f7c456081355d06af18e6e9",
            "45e8cdfafa294ac6ac55b35dc197aea8",
            "641bd40772c549b9acac1e8b4eaaf159",
            "5b8c6549b9f641cd84dbe2935a77a55f",
            "26d0ed4ee0ec4806995f220e930231e3",
            "504126222da944f4aa2c66054f2b51ad",
            "fc6a86d50e424c28b56c91e053e378ae",
            "8c03b3221c9b43229d94f67eccd46720",
            "70bc790041d248b5a7975e07733af151",
            "65e6c64b0d884985b47b5e87140fa8a5",
            "061ebaf7fee440a99243f3c644eff665",
            "f33c35d32c1144c3a955a7dfbdddd072",
            "ee8aab8ea45a4b97a711b75ce22c690b",
            "c9ed536cb7d5473e8ca540bc13075558",
            "3bcdd42de81f4e5ea04b27cd27589940",
            "8a81ca84330d47469550d88fc364ce0a",
            "1c290d25aaeb4a9eb27b7991b588dd2a",
            "9ce8179768864e16af19a8c39f60b8e9",
            "b6ea14e27878426db0d477c29fc8abb5",
            "712ec95829ad412fb0870ee15b9515b4",
            "546bd45d3b8545e4948bca58031624bc",
            "2d424fdb5d6843d286a346e5edc961d2",
            "a48c5ed83bc8441994d266510700f66b",
            "4c21a512b13647b5a1dcd857c197ff0c",
            "6d4382e5117d476299035deaccf92a8a",
            "542cf58eb56f4048a4b8581930997dac",
            "195ad93046e34f04bad3b54a95780b60",
            "6651f2dc937c412283a56669888d9fa1",
            "e177e305279a4e978ab324b76aaea00d",
            "1fe80cffd8154fa28bccaded61509407",
            "c708833e27c6493993ff81f48f5ccf03",
            "0a0d20bb25a244c392ee21a6a6989cbe",
            "9ef6689257844249a2ac3b5d6dd74716",
            "71b9889592494caba854e3a78cf1fe34",
            "a57945affbbf48d2ae033e9e911d83ac",
            "14ceee47ec144b3bbfc4567306689b3a",
            "e2d057c108ea49de9f0c850f6d356128",
            "1e348655148e4fccb98da0c7df0f77a8",
            "4bc893e6fd0342d2b4a666453bfff906",
            "aed4d1fa00284488b94bf84bf5e9b650",
            "0fac60548c2c4b0fad9167c8141daf69",
            "adeb4ba786834236bff268ce3718eaa8",
            "181ea86b0d5047bcaad0042a5ae60365",
            "7b0d0f9d8f5249bb9857efddec250ca5",
            "638ea08b8a25434f93456e6a63b86e29",
            "02338ed07f7e4dc98e189cf538883666",
            "17996b5857c048d78eb49274f974e8b8",
            "5664821d90574468b0c1b3a28d955c73",
            "aed99507db5645f296fd35ba680d1593",
            "8827ab7e2e3e4e8d84b09d1434c51f4c",
            "0b97e9f8d6cf45a68183b10777f29f8d",
            "657747455ef34fc692ee8c7036477ff1",
            "bce688fa27234dadb99e9d5d6e92c97b",
            "95fcde2c002b4a88b34e3a797811f22a",
            "3ea2a1c478a74633b5d502f5c91304d8",
            "0186e2de68ee415491667fb6f08bc049",
            "e87d91d399c2445f986af3ea156793e6",
            "46d346a20b4441918bb79535eab950e7",
            "417c5f25ff2742b4998c05d5e56b2916",
            "4f9ea42c5933426a943eb6a1a945c908",
            "9f596af298ea45ff9e46c8763bbd46c5",
            "55e87b4e804f4ccc87a201c38b075dd2",
            "ea4036ae357c40489dbbb29d83fd4c5e",
            "0a3d6b52075949898ddf028051087ab1",
            "91a0cfea2c1248d49ff438e4ca7d8d00",
            "afa2469de89f4497aa6ceb29933e1840",
            "765a0b7207954e4d8463407d82756a6b",
            "7f91bd0c70ae437dad97f0be3f621a63",
            "788f86bffb6f44f9b707846c45938a5a",
            "4c98adb1915642c8905b394717d6e380",
            "b1bff75c8e6a4e63ba3ff191f2d08fa7",
            "c5d5c883f1224298ba0d88789d059285",
            "f4f47deb1c9f4723a088d7ec25a3620c",
            "68e9050d4d544c2286f1e5859e94e684",
            "7aa85ceb4c54453dba8700d0090547f4",
            "eafe186de9634a4fa5bdfe548be7ba7a",
            "746fb0e30363412cab818485bec37666",
            "a120da82282c410c9b176a3b5e1efa73",
            "9f59c3dbda004165acbfe97ff63db68d",
            "a953375ea88541d593d9fa2ec23884e2",
            "714cde3f87574c349fb632ece5f1f9b3",
            "b2ab2d02e3be4ff5a6a86713ac0e21a8",
            "602174e8aa6f449b850701bf1929ef5b",
            "8e4ea10ed0864c028f946bc18501cbe1",
            "d57346119746493bb688aa8353430d8c",
            "1816d6b7ce9445a9a5da7da1c2c231e9",
            "74563ec9ca824249a881f701ece625c7",
            "e84c64b6db974319b887eeec5f454c67",
            "e18b302fbc86429089cdefbc9d4eebfa",
            "6519fd5d93ef402ea21e61d3f1fcea4f",
            "16fc5385534b4bd0a673982540bc7a0e",
            "84f04926655a4fb4980c2e973fb0f582",
            "918a0f08981f424caef6bc761cf0c1b8",
            "2518090b65f74967887e91facf9f4d4a",
            "fb4f867ba5e8466fa47b9151ed09c2da",
            "6d263d3ebf9a428e8652d1214ceeeafc",
            "849cae3a51834f28ae8fd7a3b27338d8",
            "4339008d1ef64becba3b00bf33fb8ec3",
            "cd52c23c9663404899e323e940eabe93",
            "3a4a687cf4524d43843a1d331012a85b",
            "08dc0ab835cc45e29d43411df07fa496",
            "b22cde5b48414ceb833aa6c0fdb2fa91",
            "73f24017b51b4f0894002c362ac1cc7c",
            "ad64494da7ff41428007e5b68f76bf6b",
            "97f87d2107cf489aa7d67c18b999f596",
            "8663c8d379e14408aef314f720578a63",
            "614f3e1976dc49ff80ddbec1f1b12162",
            "3264a65a4ec44fd3bafc8f6b0c6bfc5c",
            "e2f43866c9394d2eb8af92f3099e99a6",
            "1639e59c6ba34bbc85f5c4348b0f0aa0",
            "a3e074056d774d7fb74e07fd1fa0d2a5",
            "2188f90746fc48a7b1f005c73a1d1d68",
            "5a98fb33b14047f0b21af3aafa24411d",
            "20765ce1aa394cf292db846dd46bd89e",
            "a07bc83827da474381be6910d27b9dd7",
            "5c243b0359894d69870b343db16075d1",
            "54f96f9ec0cf452cbc15d89f2f5518f5",
            "5729eaf583eb4745bdeff6c9462aa8b7",
            "3e2366f312674345adb7c7087a0d0b73",
            "b04a14a84c344840bc9df7190c325c8b",
            "9b33b56c86a5460f91ce72f91d65a833",
            "0409ec485c0940d4ad434790e6f173ef",
            "3a433de6e8bf4a79918515b6ca5ee7c8",
            "69c1480923a841278a52c44601d7bc45",
            "ea676678ba364e97bd370aff0ab18f58",
            "7f951f4f2b1042a2b5d9e7277370c5b0",
            "1685083e8d9040a38f88e5f7cbf97f0c",
            "32a9f6bc7d98440d8e7931e45295968f",
            "763deb831c1d434badd03e524b5756aa",
            "eb0867a6bfea4ab5b7cba44109d1d9f9",
            "0741aa03979449f8bd53c7c801597a4a",
            "3055acd9a0244a5fb45c8d64606a1fb9",
            "072f12250f52415ca7c7e7dbf424b000",
            "8116d345803649d996bdea0d2061859e",
            "56ed9693d28e4f83b20d10ee41def089",
            "9f6e54ead17c4fabb0d1cbfd49e98eb8",
            "29bae6ca4b5c42c1b6503dc19485550e",
            "144c6d93b7fb403a911b02347ee6c357",
            "2b1601f8ab5e40d2ad7b95de1173b0a2",
            "e36587cc847d4d06afb44c8bd03844b0",
            "f7f616baa779444cb1ad5b26ab8dd29a",
            "cf3432c27a3d40649d86c09f7ac29a78",
            "4e2a8c7faba54b14a6e5bad46df19c83",
            "e43a08e0d5154c69bf0cb4bc33cc6062",
            "dfd008a66d794e87bf9d09a5465082d7",
            "bd132bbab34d4257944ab1de87b3f6d5",
            "539988e22986430f9e1c7702a398d09c",
            "c21812cfd6c745bc939e4c784da6ee14",
            "bd1880975e394ccab10f70d128293bb0",
            "eb5b02f0aba14d2099b27ccbc2618b60",
            "cc3ed2ad8a8b40e4880aa33e97607c5e",
            "5a2428a0cd73437a8e136717efd1dc9c",
            "0319ce141c834b69b80bdb20f37cdc04"
          ]
        },
        "collapsed": true,
        "outputId": "81d0986d-a2a8-4d24-c444-f91581e7ae0a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting processing of 200 items from index 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing batches:   0%|          | 0/20 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('WebSocketCommonProtocol.ensure_open', \"Check that the WebSocket connection is open.\\n\\n        Raise :exc:`~websockets.exceptions.ConnectionClosed` if it isn't.\"), ('WebSocketCommonProtocol.transfer_data', 'Read incoming messages and put them in a queue.\\n\\n        This coroutine runs in a task until the closing handshake is started.'), ('WebSocketCommonProtocol.read_message', 'Read a single message from the connection.\\n\\n        Re-assemble data frames if the message is fragmented.\\n\\n        Return ``None`` when the closing handshake is started.'), ('WebSocketCommonProtocol.read_data_frame', 'Read a single data frame from the connection.\\n\\n        Process control frames received before the next data frame.\\n\\n        Return ``None`` if a close frame is encountered before any data frame.'), ('WebSocketCommonProtocol.read_frame', 'Read a single frame from the connection.'), ('WebSocketCommonProtocol.write_close_frame', 'Write a close frame if and only if the connection state is OPEN.\\n\\n        This dedicated coroutine must be used for writing close frames to\\n        ensure that at most one close frame is sent on a given connection.'), ('WebSocketCommonProtocol.keepalive_ping', 'Send a Ping frame and wait for a Pong frame at regular intervals.\\n\\n        This coroutine exits when the connection terminates and one of the\\n        following happens:\\n        - :meth:`ping` raises :exc:`ConnectionClosed`, or\\n        - :meth:`close_connection` cancels :attr:`keepalive_ping_task`.'), ('WebSocketCommonProtocol.close_connection', \"7.1.1. Close the WebSocket Connection\\n\\n        When the opening handshake succeeds, :meth:`connection_open` starts\\n        this coroutine in a task. It waits for the data transfer phase to\\n        complete then it closes the TCP connection cleanly.\\n\\n        When the opening handshake fails, :meth:`fail_connection` does the\\n        same. There's no data transfer phase in that case.\"), ('WebSocketCommonProtocol.wait_for_connection_lost', 'Wait until the TCP connection is closed or ``self.close_timeout`` elapses.\\n\\n        Return ``True`` if the connection is closed and ``False`` otherwise.'), ('WebSocketCommonProtocol.fail_connection', '7.1.7. Fail the WebSocket Connection\\n\\n        This requires:\\n\\n        1. Stopping all processing of incoming data, which means cancelling\\n           :attr:`transfer_data_task`. The close code will be 1006 unless a\\n           close frame was received earlier.\\n\\n        2. Sending a close frame with an appropriate code if the opening\\n           handshake succeeded and the other side is likely to process it.\\n\\n        3. Closing the connection. :meth:`close_connection` takes care of\\n           this once :attr:`transfer_data_task` exits after being canceled.\\n\\n        (The specification describes these steps in the opposite order.)')]\n",
            "Batch 0: 10 successful, 0 failed out of 10 items\n",
            "Processed 10 items in 26.30 seconds. Rate: 0.38 items/sec\n",
            "Processed 10 items in 26.30 seconds. Rate: 0.38 items/sec\n",
            "Creating Hugging Face dataset\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "43753ead9a1b455e855523e3d8571cb8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading dataset to mrinjera/testing...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "20a70b26ea2c41df92d5d197393a1b87"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f939ec2848504f0e89a3ca7fbf630671"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading...:   0%|          | 0.00/5.55k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8e8709c2a7434771b5c78e450f59f342"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/377 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d87b31f113d54b90be00556e38a36798"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing batches:   5%|▌         | 1/20 [00:29<09:20, 29.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully uploaded dataset to https://huggingface.co/datasets/mrinjera/testing\n",
            "[('WebSocketCommonProtocol.abort_keepalive_pings', \"Raise ConnectionClosed in pending keepalive pings.\\n\\n        They'll never receive a pong once the connection is closed.\"), ('WebSocketCommonProtocol.connection_made', \"Configure write buffer limits.\\n\\n        The high-water limit is defined by ``self.write_limit``.\\n\\n        The low-water limit currently defaults to ``self.write_limit // 4`` in\\n        :meth:`~asyncio.WriteTransport.set_write_buffer_limits`, which should\\n        be all right for reasonable use cases of this library.\\n\\n        This is the earliest point where we can get hold of the transport,\\n        which means it's the best point for configuring it.\"), ('WebSocketCommonProtocol.eof_received', \"Close the transport after receiving EOF.\\n\\n        Since Python 3.5, `:meth:~StreamReaderProtocol.eof_received` returns\\n        ``True`` on non-TLS connections.\\n\\n        See http://bugs.python.org/issue24539 for more information.\\n\\n        This is inappropriate for websockets for at least three reasons:\\n\\n        1. The use case is to read data until EOF with self.reader.read(-1).\\n           Since websockets is a TLV protocol, this never happens.\\n\\n        2. It doesn't work on TLS connections. A falsy value must be\\n           returned to have the same behavior on TLS and plain connections.\\n\\n        3. The websockets protocol has its own closing handshake. Endpoints\\n           close the TCP connection after sending a close frame.\\n\\n        As a consequence we revert to the previous, more useful behavior.\"), ('WebSocketCommonProtocol.connection_lost', '7.1.4. The WebSocket Connection is Closed.'), ('build_request', 'Build a handshake request to send to the server.\\n\\n    Return the ``key`` which must be passed to :func:`check_response`.'), ('check_request', \"Check a handshake request received from the client.\\n\\n    If the handshake is valid, this function returns the ``key`` which must be\\n    passed to :func:`build_response`.\\n\\n    Otherwise it raises an :exc:`~websockets.exceptions.InvalidHandshake`\\n    exception and the server must return an error like 400 Bad Request.\\n\\n    This function doesn't verify that the request is an HTTP/1.1 or higher GET\\n    request and doesn't perform Host and Origin checks. These controls are\\n    usually performed earlier in the HTTP request handling code. They're the\\n    responsibility of the caller.\"), ('build_response', 'Build a handshake response to send to the client.\\n\\n    ``key`` comes from :func:`check_request`.'), ('check_response', \"Check a handshake response received from the server.\\n\\n    ``key`` comes from :func:`build_request`.\\n\\n    If the handshake is valid, this function returns ``None``.\\n\\n    Otherwise it raises an :exc:`~websockets.exceptions.InvalidHandshake`\\n    exception.\\n\\n    This function doesn't verify that the response is an HTTP/1.1 or higher\\n    response with a 101 status code. These controls are the responsibility of\\n    the caller.\"), ('_build_parameters', 'Build a list of ``(name, value)`` pairs for some compression parameters.'), ('_extract_parameters', 'Extract compression parameters from a list of ``(name, value)`` pairs.\\n\\n    If ``is_server`` is ``True``, ``client_max_window_bits`` may be provided\\n    without a value. This is only allow in handshake requests.')]\n",
            "Batch 1: 10 successful, 0 failed out of 10 items\n",
            "Processed 20 items in 60.27 seconds. Rate: 0.33 items/sec\n",
            "Creating Hugging Face dataset\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ae49dfac56804be3bf9c99b174fb70a7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading dataset to mrinjera/testing...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2fdcc6fc74164ece89e1d218712a0863"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d3a568a2069242b9b468b38a77caea5c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading...:   0%|          | 0.00/7.68k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3e16779eb6d541bd8fcc61d77cceab2c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/378 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "57be6f45a5914be88a95c908184a3998"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing batches:  10%|█         | 2/20 [01:02<09:31, 31.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully uploaded dataset to https://huggingface.co/datasets/mrinjera/testing\n",
            "[('PerMessageDeflate.decode', 'Decode an incoming frame.'), ('PerMessageDeflate.encode', 'Encode an outgoing frame.'), ('ClientPerMessageDeflateFactory.get_request_params', 'Build request parameters.'), ('ClientPerMessageDeflateFactory.process_response_params', 'Process response parameters.\\n\\n        Return an extension instance.'), ('ServerPerMessageDeflateFactory.process_request_params', 'Process request parameters.\\n\\n        Return response params and an extension instance.'), ('apply_mask', 'Apply masking to the data of a WebSocket message.\\n\\n    ``data`` and ``mask`` are bytes-like objects.\\n\\n    Return :class:`bytes`.'), ('format_close', 'Display a human-readable version of the close code and reason.'), ('ServerExtensionFactory.process_request_params', 'Process request parameters received from the client.\\n\\n        ``params`` is a list of (name, value) pairs.\\n\\n        ``accepted_extensions`` is a list of previously accepted extensions.\\n\\n        To accept the offer, return a 2-uple containing:\\n\\n        - response parameters: a list of (name, value) pairs\\n        - an extension: an instance of a subclass of :class:`Extension`\\n\\n        To reject the offer, raise\\n        :exc:`~websockets.exceptions.NegotiationError`.'), ('run_services', 'Serves a number of services for a contextual block.\\n    The caller can specify a number of service classes then serve them either\\n    stopping (default) or killing them on exiting the contextual block.\\n\\n\\n    Example::\\n\\n        with run_services(config, Foobar, Spam) as runner:\\n            # interact with services and stop them on exiting the block\\n\\n        # services stopped\\n\\n\\n    Additional configuration available to :class:``ServiceRunner`` instances\\n    can be specified through keyword arguments::\\n\\n        with run_services(config, Foobar, Spam, kill_on_exit=True):\\n            # interact with services\\n\\n        # services killed\\n\\n    :Parameters:\\n        config : dict\\n            Configuration to instantiate the service containers with\\n        services : service definitions\\n            Services to be served for the contextual block\\n        kill_on_exit : bool (default=False)\\n            If ``True``, run ``kill()`` on the service containers when exiting\\n            the contextual block. Otherwise ``stop()`` will be called on the\\n            service containers on exiting the block.\\n\\n    :Returns: The configured :class:`ServiceRunner` instance'), ('ServiceRunner.add_service', 'Add a service class to the runner.\\n        There can only be one service class for a given service name.\\n        Service classes must be registered before calling start()')]\n",
            "Batch 2: 10 successful, 0 failed out of 10 items\n",
            "Processed 30 items in 87.76 seconds. Rate: 0.34 items/sec\n",
            "Creating Hugging Face dataset\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/30 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bf990b5d8b664f1d98726fe6c8b36908"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading dataset to mrinjera/testing...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9728c5debd0645e38fd03e9503fdb87e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c742e69e86b41c7befbf9430663a972"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading...:   0%|          | 0.00/9.41k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "738b658d55aa4b04a2bcd656515ad561"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/378 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "04798304e36c47838d5abc169ba6b29d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing batches:  15%|█▌        | 3/20 [01:30<08:27, 29.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully uploaded dataset to https://huggingface.co/datasets/mrinjera/testing\n",
            "[('ServiceRunner.start', 'Start all the registered services.\\n\\n        A new container is created for each service using the container\\n        class provided in the __init__ method.\\n\\n        All containers are started concurrently and the method will block\\n        until all have completed their startup routine.'), ('ServiceRunner.wait', 'Wait for all running containers to stop.'), ('Publisher.publish', 'Publish a message.'), ('RpcConsumer.stop', \"Stop the RpcConsumer.\\n\\n        The RpcConsumer ordinary unregisters from the QueueConsumer when the\\n        last Rpc subclass unregisters from it. If no providers were registered,\\n        we should unregister from the QueueConsumer as soon as we're asked\\n        to stop.\"), ('RpcConsumer.unregister_provider', 'Unregister a provider.\\n\\n        Blocks until this RpcConsumer is unregistered from its QueueConsumer,\\n        which only happens when all providers have asked to unregister.'), ('EventDispatcher.get_dependency', 'Inject a dispatch method onto the service instance'), ('EventHandler.broadcast_identifier', \"A unique string to identify a service instance for `BROADCAST`\\n        type handlers.\\n\\n        The `broadcast_identifier` is appended to the queue name when the\\n        `BROADCAST` handler type is used. It must uniquely identify service\\n        instances that receive broadcasts.\\n\\n        The default `broadcast_identifier` is a uuid that is set when the\\n        service starts. It will change when the service restarts, meaning\\n        that any unconsumed messages that were broadcast to the 'old' service\\n        instance will not be received by the 'new' one. ::\\n\\n            @property\\n            def broadcast_identifier(self):\\n                # use a uuid as the identifier.\\n                # the identifier will change when the service restarts and\\n                # any unconsumed messages will be lost\\n                return uuid.uuid4().hex\\n\\n        The default behaviour is therefore incompatible with reliable delivery.\\n\\n        An alternative `broadcast_identifier` that would survive service\\n        restarts is ::\\n\\n            @property\\n            def broadcast_identifier(self):\\n                # use the machine hostname as the identifier.\\n                # this assumes that only one instance of a service runs on\\n                # any given machine\\n                return socket.gethostname()\\n\\n        If neither of these approaches are appropriate, you could read the\\n        value out of a configuration file ::\\n\\n            @property\\n            def broadcast_identifier(self):\\n                return self.config['SERVICE_IDENTIFIER']  # or similar\\n\\n        Broadcast queues are exclusive to ensure that `broadcast_identifier`\\n        values are unique.\\n\\n        Because this method is a descriptor, it will be called during\\n        container creation, regardless of the configured `handler_type`.\\n        See :class:`nameko.extensions.Extension` for more details.\"), ('get_module_path', 'Return the dotted module path of `exc_type`, including the class name.\\n\\n    e.g.::\\n\\n        >>> get_module_path(MethodNotFound)\\n        >>> \"nameko.exceptions.MethodNotFound\"'), ('safe_for_serialization', 'Transform a value in preparation for serializing as json\\n\\n    no-op for strings, mappings and iterables have their entries made safe,\\n    and all other values are stringified, with a fallback value if that fails'), ('serialize', 'Serialize `self.exc` into a data dictionary representing it.')]\n",
            "Batch 3: 10 successful, 0 failed out of 10 items\n",
            "Processed 40 items in 117.96 seconds. Rate: 0.34 items/sec\n",
            "Creating Hugging Face dataset\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/40 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f4d86688063a40e192d89a5e4167ea74"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading dataset to mrinjera/testing...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c45a164706da49f49d6f9fc0328e802a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4fc027f2f87d472992c4163bf7bc81cd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading...:   0%|          | 0.00/11.8k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c0228a8f851431a903a491531b78761"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/380 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "96cb7a4a6acc4dc8946ff60978226147"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing batches:  20%|██        | 4/20 [02:00<07:59, 29.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully uploaded dataset to https://huggingface.co/datasets/mrinjera/testing\n",
            "[('deserialize', 'Deserialize `data` to an exception instance.\\n\\n    If the `exc_path` value matches an exception registered as\\n    ``deserializable``, return an instance of that exception type.\\n    Otherwise, return a `RemoteError` instance describing the exception\\n    that occurred.'), ('get_redacted_args', 'Utility function for use with entrypoints that are marked with\\n    ``sensitive_arguments`` -- e.g. :class:`nameko.rpc.Rpc` and\\n    :class:`nameko.events.EventHandler`.\\n\\n    :Parameters:\\n        entrypoint : :class:`~nameko.extensions.Entrypoint`\\n            The entrypoint that fired.\\n        args : tuple\\n            Positional arguments for the method call.\\n        kwargs : dict\\n            Keyword arguments for the method call.\\n\\n    The entrypoint should have a ``sensitive_arguments`` attribute, the value\\n    of which is a string or tuple of strings specifying the arguments or\\n    partial arguments that should be redacted. To partially redact an argument,\\n    the following syntax is used::\\n\\n        <argument-name>.<dict-key>[<list-index>]\\n\\n    :Returns:\\n        A dictionary as returned by :func:`inspect.getcallargs`, but with\\n        sensitive arguments or partial arguments redacted.\\n\\n    .. note::\\n\\n        This function does not raise if one of the ``sensitive_arguments``\\n        doesn\\'t match or partially match the calling ``args`` and ``kwargs``.\\n        This allows \"fuzzier\" pattern matching (e.g. redact a field if it is\\n        present, and otherwise do nothing).\\n\\n        To avoid exposing sensitive arguments through a typo, it is recommend\\n        to test the configuration of each entrypoint with\\n        ``sensitive_arguments`` individually. For example:\\n\\n        .. code-block:: python\\n\\n            class Service(object):\\n                @rpc(sensitive_arguments=\"foo.bar\")\\n                def method(self, foo):\\n                    pass\\n\\n            container = ServiceContainer(Service, {})\\n            entrypoint = get_extension(container, Rpc, method_name=\"method\")\\n\\n            # no redaction\\n            foo = \"arg\"\\n            expected_foo = {\\'foo\\': \"arg\"}\\n            assert get_redacted_args(entrypoint, foo) == expected\\n\\n            # \\'bar\\' key redacted\\n            foo = {\\'bar\\': \"secret value\", \\'baz\\': \"normal value\"}\\n            expected = {\\'foo\\': {\\'bar\\': \"********\", \\'baz\\': \"normal value\"}}\\n            assert get_redacted_args(entrypoint, foo) == expected\\n\\n    .. seealso::\\n\\n        The tests for this utility demonstrate its full usage:\\n        :class:`test.test_utils.TestGetRedactedArgs`'), ('import_from_path', 'Import and return the object at `path` if it exists.\\n\\n    Raises an :exc:`ImportError` if the object is not found.'), ('sanitize_url', 'Redact password in urls.'), ('WebSocketHub.get_subscriptions', 'Returns a list of all the subscriptions of a socket.'), ('WebSocketHub.subscribe', 'Subscribes a socket to a channel.'), ('WebSocketHub.unsubscribe', 'Unsubscribes a socket from a channel.'), ('WebSocketHub.broadcast', 'Broadcasts an event to all sockets listening on a channel.'), ('WebSocketHub.unicast', 'Sends an event to a single socket.  Returns `True` if that\\n        worked or `False` if not.'), ('make_timing_logger', 'Return a timing logger.\\n\\n    Usage::\\n\\n        >>> logger = logging.getLogger(\\'foobar\\')\\n        >>> log_time = make_timing_logger(\\n        ...     logger, level=logging.INFO, precision=2)\\n        >>>\\n        >>> with log_time(\"hello %s\", \"world\"):\\n        ...     time.sleep(1)\\n        INFO:foobar:hello world in 1.00s')]\n",
            "Batch 4: 10 successful, 0 failed out of 10 items\n",
            "Processed 50 items in 151.55 seconds. Rate: 0.33 items/sec\n",
            "Creating Hugging Face dataset\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "591e2f9de6ea433f8b83d133ce36d96e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading dataset to mrinjera/testing...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4275b9f655a44465b8500cb4662f344b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8fc8131fa3cc4bdda63ecab6139eab0c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading...:   0%|          | 0.00/14.2k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eff9db04390840ec8b63a0e575626d01"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/381 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe2d1c7648294dab9ed225f02c28b1e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing batches:  25%|██▌       | 5/20 [02:34<07:50, 31.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully uploaded dataset to https://huggingface.co/datasets/mrinjera/testing\n",
            "[('WebServer.get_wsgi_server', 'Get the WSGI server used to process requests.'), ('get_event_exchange', 'Get an exchange for ``service_name`` events.'), ('event_dispatcher', 'Return a function that dispatches nameko events.'), ('fail_fast_imap', 'Run a function against each item in a given list, yielding each\\n    function result in turn, where the function call is handled in a\\n    :class:`~eventlet.greenthread.GreenThread` spawned by the provided pool.\\n\\n    If any function raises an exception, all other ongoing threads are killed,\\n    and the exception is raised to the caller.\\n\\n    This function is similar to :meth:`~eventlet.greenpool.GreenPool.imap`.\\n\\n    :param pool: Pool to spawn function threads from\\n    :type pool: eventlet.greenpool.GreenPool\\n    :param call: Function call to make, expecting to receive an item from the\\n        given list'), ('Timer._run', 'Runs the interval loop.'), ('QueueConsumer.stop', \"Stop the queue-consumer gracefully.\\n\\n        Wait until the last provider has been unregistered and for\\n        the ConsumerMixin's greenthread to exit (i.e. until all pending\\n        messages have been acked or requeued and all consumers stopped).\"), ('QueueConsumer.kill', 'Kill the queue-consumer.\\n\\n        Unlike `stop()` any pending message ack or requeue-requests,\\n        requests to remove providers, etc are lost and the consume thread is\\n        asked to terminate as soon as possible.'), ('QueueConsumer.connection', \"Provide the connection parameters for kombu's ConsumerMixin.\\n\\n        The `Connection` object is a declaration of connection parameters\\n        that is lazily evaluated. It doesn't represent an established\\n        connection to the broker at this point.\"), ('QueueConsumer.get_consumers', 'Kombu callback to set up consumers.\\n\\n        Called after any (re)connection to the broker.'), ('QueueConsumer.on_iteration', 'Kombu callback for each `drain_events` loop iteration.')]\n",
            "Batch 5: 10 successful, 0 failed out of 10 items\n",
            "Processed 60 items in 177.91 seconds. Rate: 0.34 items/sec\n",
            "Creating Hugging Face dataset\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/60 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "235e4e5c33bf4d6899d6167be3734013"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading dataset to mrinjera/testing...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c67ea1380f9b4e1d93c00884f6728bde"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b1acdbd1bca4eff8014c00c9105ccea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading...:   0%|          | 0.00/15.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "801e9059776e4d29ba804761164e5232"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/381 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "48d3bc750e724142a4112552aa5b2c55"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing batches:  30%|███       | 6/20 [03:00<06:54, 29.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully uploaded dataset to https://huggingface.co/datasets/mrinjera/testing\n",
            "[('QueueConsumer.on_consume_ready', 'Kombu callback when consumers are ready to accept messages.\\n\\n        Called after any (re)connection to the broker.'), ('make_nameko_helper', 'Create a fake module that provides some convenient access to nameko\\n    standalone functionality for interactive shell usage.'), ('iter_extensions', 'Depth-first iterator over sub-extensions on `extension`.'), ('Extension.bind', 'Get an instance of this Extension to bind to `container`.'), ('SharedExtension.bind', 'Bind implementation that supports sharing.'), ('DependencyProvider.bind', 'Get an instance of this Dependency to bind to `container` with\\n        `attr_name`.'), ('ProviderCollector.wait_for_providers', 'Wait for any providers registered with the collector to have\\n        unregistered.\\n\\n        Returns immediately if no providers were ever registered.'), ('Entrypoint.bind', 'Get an instance of this Entrypoint to bind to `container` with\\n        `method_name`.'), ('ServiceContainer.start', 'Start a container by starting all of its extensions.'), ('ServiceContainer.stop', \"Stop the container gracefully.\\n\\n        First all entrypoints are asked to ``stop()``.\\n        This ensures that no new worker threads are started.\\n\\n        It is the extensions' responsibility to gracefully shut down when\\n        ``stop()`` is called on them and only return when they have stopped.\\n\\n        After all entrypoints have stopped the container waits for any\\n        active workers to complete.\\n\\n        After all active workers have stopped the container stops all\\n        dependency providers.\\n\\n        At this point there should be no more managed threads. In case there\\n        are any managed threads, they are killed by the container.\")]\n",
            "Batch 6: 10 successful, 0 failed out of 10 items\n",
            "Processed 70 items in 203.94 seconds. Rate: 0.34 items/sec\n",
            "Creating Hugging Face dataset\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/70 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "55d655ecc0d94b07a466813a494304a7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading dataset to mrinjera/testing...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2843ffadc58746f48041b82a51ba10b0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eac0c2962bab4dc9a151e81852bc9f88"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading...:   0%|          | 0.00/16.9k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "28b5a3df8020452098bd9b459984aa09"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/381 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1a17ab3cfb9d454aa3d24b68d3edee59"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing batches:  35%|███▌      | 7/20 [03:26<06:09, 28.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully uploaded dataset to https://huggingface.co/datasets/mrinjera/testing\n",
            "[('ServiceContainer.kill', 'Kill the container in a semi-graceful way.\\n\\n        Entrypoints are killed, followed by any active worker threads.\\n        Next, dependencies are killed. Finally, any remaining managed threads\\n        are killed.\\n\\n        If ``exc_info`` is provided, the exception will be raised by\\n        :meth:`~wait``.'), ('ServiceContainer.spawn_worker', 'Spawn a worker thread for running the service method decorated\\n        by `entrypoint`.\\n\\n        ``args`` and ``kwargs`` are used as parameters for the service method.\\n\\n        ``context_data`` is used to initialize a ``WorkerContext``.\\n\\n        ``handle_result`` is an optional function which may be passed\\n        in by the entrypoint. It is called with the result returned\\n        or error raised by the service method. If provided it must return a\\n        value for ``result`` and ``exc_info`` to propagate to dependencies;\\n        these may be different to those returned by the service method.'), ('ServiceContainer.spawn_managed_thread', \"Spawn a managed thread to run ``fn`` on behalf of an extension.\\n        The passed `identifier` will be included in logs related to this\\n        thread, and otherwise defaults to `fn.__name__`, if it is set.\\n\\n        Any uncaught errors inside ``fn`` cause the container to be killed.\\n\\n        It is the caller's responsibility to terminate their spawned threads.\\n        Threads are killed automatically if they are still running after\\n        all extensions are stopped during :meth:`ServiceContainer.stop`.\\n\\n        Extensions should delegate all thread spawning to the container.\"), ('ServiceContainer._kill_worker_threads', 'Kill any currently executing worker threads.\\n\\n        See :meth:`ServiceContainer.spawn_worker`'), ('ServiceContainer._kill_managed_threads', 'Kill any currently executing managed threads.\\n\\n        See :meth:`ServiceContainer.spawn_managed_thread`'), ('ConsumeEvent.wait', 'Makes a blocking call to its queue_consumer until the message\\n        with the given correlation_id has been processed.\\n\\n        By the time the blocking call exits, self.send() will have been called\\n        with the body of the received message\\n        (see :meth:`~nameko.rpc.ReplyListener.handle_message`).\\n\\n        Exceptions are raised directly.'), ('StatefulBrowser.new_control', 'Call :func:`Form.new_control` on the currently selected form.'), ('StatefulBrowser.open', \"Open the URL and store the Browser's state in this object.\\n        All arguments are forwarded to :func:`Browser.get`.\\n\\n        :return: Forwarded from :func:`Browser.get`.\"), ('StatefulBrowser.open_fake_page', \"Mock version of :func:`open`.\\n\\n        Behave as if opening a page whose text is ``page_text``, but do not\\n        perform any network access. If ``url`` is set, pretend it is the page's\\n        URL. Useful mainly for testing.\"), ('StatefulBrowser.open_relative', 'Like :func:`open`, but ``url`` can be relative to the currently\\n        visited page.')]\n",
            "Batch 7: 10 successful, 0 failed out of 10 items\n",
            "Processed 80 items in 234.44 seconds. Rate: 0.34 items/sec\n",
            "Creating Hugging Face dataset\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/80 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c9c216201ef64476a0ed958c05e22573"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading dataset to mrinjera/testing...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bc5da5dcfe334db0a580ac34568c4cd0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "872de3d78f0e42b48d5ebf400ff3b555"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading...:   0%|          | 0.00/18.8k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a4b5e277bde461981546aea0f58d48a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/381 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec6f1123991448aab9aa9b7eddb98c03"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing batches:  40%|████      | 8/20 [03:57<05:51, 29.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully uploaded dataset to https://huggingface.co/datasets/mrinjera/testing\n",
            "[('StatefulBrowser.refresh', 'Reload the current page with the same request as originally done.\\n        Any change (`select_form`, or any value filled-in in the form) made to\\n        the current page before refresh is discarded.\\n\\n        :raise ValueError: Raised if no refreshable page is loaded, e.g., when\\n            using the shallow ``Browser`` wrapper functions.\\n\\n        :return: Response of the request.'), ('StatefulBrowser.select_form', 'Select a form in the current page.\\n\\n        :param selector: CSS selector or a bs4.element.Tag object to identify\\n            the form to select.\\n            If not specified, ``selector`` defaults to \"form\", which is\\n            useful if, e.g., there is only one form on the page.\\n            For ``selector`` syntax, see the `.select() method in BeautifulSoup\\n            <https://www.crummy.com/software/BeautifulSoup/bs4/doc/#css-selectors>`__.\\n        :param nr: A zero-based index specifying which form among those that\\n            match ``selector`` will be selected. Useful when one or more forms\\n            have the same attributes as the form you want to select, and its\\n            position on the page is the only way to uniquely identify it.\\n            Default is the first matching form (``nr=0``).\\n\\n        :return: The selected form as a soup object. It can also be\\n            retrieved later with :func:`get_current_form`.'), ('StatefulBrowser.submit_selected', 'Submit the form that was selected with :func:`select_form`.\\n\\n        :return: Forwarded from :func:`Browser.submit`.\\n\\n        If there are multiple submit input/button elements, passes ``btnName``\\n        to :func:`Form.choose_submit` on the current form to choose between\\n        them. If `update_state` is False, form will be submited but the browser\\n        state will remain unchanged. This is useful for forms that result in\\n        a download of a file. All other arguments are forwarded to\\n        :func:`Browser.submit`.'), ('StatefulBrowser.list_links', 'Display the list of links in the current page. Arguments are\\n        forwarded to :func:`links`.'), ('StatefulBrowser.links', 'Return links in the page, as a list of bs4.element.Tag objects.\\n\\n        To return links matching specific criteria, specify ``url_regex``\\n        to match the *href*-attribute, or ``link_text`` to match the\\n        *text*-attribute of the Tag. All other arguments are forwarded to\\n        the `.find_all() method in BeautifulSoup\\n        <https://www.crummy.com/software/BeautifulSoup/bs4/doc/#find-all>`__.'), ('StatefulBrowser.find_link', 'Find and return a link, as a bs4.element.Tag object.\\n\\n        The search can be refined by specifying any argument that is accepted\\n        by :func:`links`. If several links match, return the first one found.\\n\\n        If no link is found, raise :class:`LinkNotFoundError`.'), ('StatefulBrowser._find_link_internal', 'Wrapper around find_link that deals with convenience special-cases:\\n\\n        * If ``link`` has an *href*-attribute, then return it. If not,\\n          consider it as a ``url_regex`` argument.\\n\\n        * If searching for the link fails and debug is active, launch\\n          a browser.'), ('StatefulBrowser.follow_link', \"Follow a link.\\n\\n        If ``link`` is a bs4.element.Tag (i.e. from a previous call to\\n        :func:`links` or :func:`find_link`), then follow the link.\\n\\n        If ``link`` doesn't have a *href*-attribute or is None, treat\\n        ``link`` as a url_regex and look it up with :func:`find_link`.\\n        Any additional arguments specified are forwarded to this function.\\n\\n        If the link is not found, raise :class:`LinkNotFoundError`.\\n        Before raising, if debug is activated, list available links in the\\n        page and launch a browser.\\n\\n        :return: Forwarded from :func:`open_relative`.\"), ('StatefulBrowser.download_link', 'Downloads the contents of a link to a file. This function behaves\\n        similarly to :func:`follow_link`, but the browser state will\\n        not change when calling this function.\\n\\n        :param file: Filesystem path where the page contents will be\\n            downloaded. If the file already exists, it will be overwritten.\\n\\n        Other arguments are the same as :func:`follow_link` (``link``\\n        can either be a bs4.element.Tag or a URL regex, other\\n        arguments are forwarded to :func:`find_link`).\\n\\n        :return: `requests.Response\\n            <http://docs.python-requests.org/en/master/api/#requests.Response>`__\\n            object.'), ('StatefulBrowser.launch_browser', 'Launch a browser to display a page, for debugging purposes.\\n\\n        :param: soup: Page contents to display, supplied as a bs4 soup object.\\n            Defaults to the current page of the ``StatefulBrowser`` instance.')]\n",
            "Batch 8: 10 successful, 0 failed out of 10 items\n",
            "Processed 90 items in 267.86 seconds. Rate: 0.34 items/sec\n",
            "Creating Hugging Face dataset\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/90 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5c556d3c3e344121b9d726e05afd6224"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading dataset to mrinjera/testing...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1e8973399d0e46bdb66c21d5c5e457a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "67a3200665ec491b9ae33fee98c43722"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading...:   0%|          | 0.00/21.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "96f23ac19d0647aab0d83ebb5f47a8ca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/381 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dfdb78bb020746559f0552cbf8fb5640"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing batches:  45%|████▌     | 9/20 [04:30<05:33, 30.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully uploaded dataset to https://huggingface.co/datasets/mrinjera/testing\n",
            "[('Form.set_input', 'Fill-in a set of fields in a form.\\n\\n        Example: filling-in a login/password form\\n\\n        .. code-block:: python\\n\\n           form.set_input({\"login\": username, \"password\": password})\\n\\n        This will find the input element named \"login\" and give it the\\n        value ``username``, and the input element named \"password\" and\\n        give it the value ``password``.'), ('Form.uncheck_all', 'Remove the *checked*-attribute of all input elements with\\n        a *name*-attribute given by ``name``.'), ('Form.check', 'For backwards compatibility, this method handles checkboxes\\n        and radio buttons in a single call. It will not uncheck any\\n        checkboxes unless explicitly specified by ``data``, in contrast\\n        with the default behavior of :func:`~Form.set_checkbox`.'), ('Form.set_checkbox', 'Set the *checked*-attribute of input elements of type \"checkbox\"\\n        specified by ``data`` (i.e. check boxes).\\n\\n        :param data: Dict of ``{name: value, ...}``.\\n            In the family of checkboxes whose *name*-attribute is ``name``,\\n            check the box whose *value*-attribute is ``value``. All boxes in\\n            the family can be checked (unchecked) if ``value`` is True (False).\\n            To check multiple specific boxes, let ``value`` be a tuple or list.\\n        :param uncheck_other_boxes: If True (default), before checking any\\n            boxes specified by ``data``, uncheck the entire checkbox family.\\n            Consider setting to False if some boxes are checked by default when\\n            the HTML is served.'), ('Form.set_radio', 'Set the *checked*-attribute of input elements of type \"radio\"\\n        specified by ``data`` (i.e. select radio buttons).\\n\\n        :param data: Dict of ``{name: value, ...}``.\\n            In the family of radio buttons whose *name*-attribute is ``name``,\\n            check the radio button whose *value*-attribute is ``value``.\\n            Only one radio button in the family can be checked.'), ('Form.set_textarea', 'Set the *string*-attribute of the first textarea element\\n        specified by ``data`` (i.e. set the text of a textarea).\\n\\n        :param data: Dict of ``{name: value, ...}``.\\n            The textarea whose *name*-attribute is ``name`` will have\\n            its *string*-attribute set to ``value``.'), ('Form.set_select', \"Set the *selected*-attribute of the first option element\\n        specified by ``data`` (i.e. select an option from a dropdown).\\n\\n        :param data: Dict of ``{name: value, ...}``.\\n            Find the select element whose *name*-attribute is ``name``.\\n            Then select from among its children the option element whose\\n            *value*-attribute is ``value``. If no matching *value*-attribute\\n            is found, this will search for an option whose text matches\\n            ``value``. If the select element's *multiple*-attribute is set,\\n            then ``value`` can be a list or tuple to select multiple options.\"), ('Form.set', 'Set a form element identified by ``name`` to a specified ``value``.\\n        The type of element (input, textarea, select, ...) does not\\n        need to be given; it is inferred by the following methods:\\n        :func:`~Form.set_checkbox`,\\n        :func:`~Form.set_radio`,\\n        :func:`~Form.set_input`,\\n        :func:`~Form.set_textarea`,\\n        :func:`~Form.set_select`.\\n        If none of these methods find a matching element, then if ``force``\\n        is True, a new element (``<input type=\"text\" ...>``) will be\\n        added using :func:`~Form.new_control`.\\n\\n        Example: filling-in a login/password form with EULA checkbox\\n\\n        .. code-block:: python\\n\\n            form.set(\"login\", username)\\n            form.set(\"password\", password)\\n            form.set(\"eula-checkbox\", True)\\n\\n        Example: uploading a file through a ``<input type=\"file\"\\n        name=\"tagname\">`` field (provide the path to the local file,\\n        and its content will be uploaded):\\n\\n        .. code-block:: python\\n\\n            form.set(\"tagname\") = path_to_local_file'), ('Form.new_control', 'Add a new input element to the form.\\n\\n        The arguments set the attributes of the new element.'), ('Form.choose_submit', \"Selects the input (or button) element to use for form submission.\\n\\n        :param submit: The bs4.element.Tag (or just its *name*-attribute) that\\n            identifies the submit element to use. If ``None``, will choose the\\n            first valid submit element in the form, if one exists.\\n\\n        To simulate a normal web browser, only one submit element must be\\n        sent. Therefore, this does not need to be called if there is only\\n        one submit element in the form.\\n\\n        If the element is not found or if multiple elements match, raise a\\n        :class:`LinkNotFoundError` exception.\\n\\n        Example: ::\\n\\n            browser = mechanicalsoup.StatefulBrowser()\\n            browser.open(url)\\n            form = browser.select_form()\\n            form.choose_submit('form_name_attr')\\n            browser.submit_selected()\")]\n",
            "Batch 9: 10 successful, 0 failed out of 10 items\n",
            "Processed 100 items in 302.53 seconds. Rate: 0.33 items/sec\n",
            "Creating Hugging Face dataset\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "172dc414d9be4530a5b83d66230d8f0a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading dataset to mrinjera/testing...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b53dd0f1dbff41eea3bb0cedd2e0b298"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1207c790692c439882d79f9c02a19e5f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading...:   0%|          | 0.00/24.1k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e91ad4bd03844552ab75f5d5feb7f6e3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/381 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a5e97ffbebe04925aeeb49d39d5cea94"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing batches:  50%|█████     | 10/20 [05:05<05:17, 31.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully uploaded dataset to https://huggingface.co/datasets/mrinjera/testing\n",
            "[('Form.print_summary', 'Print a summary of the form.\\n\\n        May help finding which fields need to be filled-in.'), ('Browser.__looks_like_html', 'Guesses entity type when Content-Type header is missing.\\n        Since Content-Type is not strictly required, some servers leave it out.'), ('Browser.add_soup', 'Attaches a soup object to a requests response.'), ('Browser.set_user_agent', 'Replaces the current user agent in the requests session headers.'), ('Browser.request', \"Straightforward wrapper around `requests.Session.request\\n        <http://docs.python-requests.org/en/master/api/#requests.Session.request>`__.\\n\\n        :return: `requests.Response\\n            <http://docs.python-requests.org/en/master/api/#requests.Response>`__\\n            object with a *soup*-attribute added by :func:`add_soup`.\\n\\n        This is a low-level function that should not be called for\\n        basic usage (use :func:`get` or :func:`post` instead). Use it if you\\n        need an HTTP verb that MechanicalSoup doesn't manage (e.g. MKCOL) for\\n        example.\"), ('Browser.get', 'Straightforward wrapper around `requests.Session.get\\n        <http://docs.python-requests.org/en/master/api/#requests.Session.get>`__.\\n\\n        :return: `requests.Response\\n            <http://docs.python-requests.org/en/master/api/#requests.Response>`__\\n            object with a *soup*-attribute added by :func:`add_soup`.'), ('Browser._request', 'Extract input data from the form to pass to a Requests session.'), ('Browser.submit', 'Prepares and sends a form request.\\n\\n        NOTE: To submit a form with a :class:`StatefulBrowser` instance, it is\\n        recommended to use :func:`StatefulBrowser.submit_selected` instead of\\n        this method so that the browser state is correctly updated.\\n\\n        :param form: The filled-out form.\\n        :param url: URL of the page the form is on. If the form action is a\\n            relative path, then this must be specified.\\n        :param \\\\\\\\*\\\\\\\\*kwargs: Arguments forwarded to `requests.Session.request\\n            <http://docs.python-requests.org/en/master/api/#requests.Session.request>`__.\\n\\n        :return: `requests.Response\\n            <http://docs.python-requests.org/en/master/api/#requests.Response>`__\\n            object with a *soup*-attribute added by :func:`add_soup`.'), ('Browser.launch_browser', 'Launch a browser to display a page, for debugging purposes.\\n\\n        :param: soup: Page contents to display, supplied as a bs4 soup object.'), ('Browser.close', 'Close the current session, if still open.')]\n",
            "Batch 10: 10 successful, 0 failed out of 10 items\n",
            "Processed 110 items in 331.25 seconds. Rate: 0.33 items/sec\n",
            "Processed 110 items in 331.25 seconds. Rate: 0.33 items/sec\n",
            "Creating Hugging Face dataset\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/110 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "78d9e566b9f54ecd94777937f10b4890"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading dataset to mrinjera/testing...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4709e89997514b18af6a876bf2104fee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cfb10e56fabe4ae99f0fbc1e6c9332ca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading...:   0%|          | 0.00/25.2k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b276ccbbd62c4cfaa423d55a7d8c99b1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/382 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "71fab81d95db4e8bac2364a25e39ed9a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing batches:  55%|█████▌    | 11/20 [05:34<04:37, 30.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully uploaded dataset to https://huggingface.co/datasets/mrinjera/testing\n",
            "[('requirements_from_file', 'Parses a pip requirements file into a list.'), ('read', 'Read the content of a file.'), ('imscatter', 'Creates a scatter plot, where each plot is shown by corresponding image'), ('pauli', 'Convert to pauli operators of universal gate model.\\n\\tRequires blueqat.'), ('make_qs', 'Make sympy symbols q0, q1, ...\\n    \\n    Args:\\n        n(int), m(int, optional):\\n            If specified both n and m, returns [qn, q(n+1), ..., qm],\\n            Only n is specified, returns[q0, q1, ..., qn].\\n\\n    Return:\\n        tuple(Symbol): Tuple of sympy symbols.'), ('nbody_separation', \"Convert n-body problem to 2-body problem.\\n    \\n    Args:\\n        expr: sympy expressions to be separated.\\n        qs: sympy's symbols to be used as supplementary variable.\\n\\n    Return:\\n        new_expr(sympy expr), constraints(sympy expr), mapping(dict(str, str -> Symbol)):\\n            `new_expr` is converted problem, `constraints` is constraints for supplementary variable.\\n            You may use `expr = new_expr + delta * constraints`, delta is floating point variable.\\n            mapping is supplementary variable's mapping.\"), ('qn_to_qubo', \"Convert Sympy's expr to QUBO.\\n    \\n    Args:\\n        expr: Sympy's quadratic expression with variable `q0`, `q1`, ...\\n    Returns:\\n        [[float]]: Returns QUBO matrix.\"), ('sel', 'Automatically create QUBO which select K qubits from N qubits\\n\\t.. code-block:: python\\n\\t\\tprint(wq.sel(5,2))\\n\\t\\t#=>\\n\\t\\t[[-3  2  2  2  2]\\n\\t\\t[ 0 -3  2  2  2]\\n\\t\\t[ 0  0 -3  2  2]\\n\\t\\t[ 0  0  0 -3  2]\\n\\t\\t[ 0  0  0  0 -3]]\\n\\t\\t\\n\\tif you set array on the 3rd params, the result likely to choose the nth qubit in the array\\n\\t.. code-block:: python\\n\\t\\tprint(wq.sel(5,2,[0,2]))\\n\\t\\t#=>\\n\\t\\t[[-3.5  2.   2.   2.   2. ]\\n\\t\\t[ 0.  -3.   2.   2.   2. ]\\n\\t\\t[ 0.   0.  -3.5  2.   2. ]\\n\\t\\t[ 0.   0.   0.  -3.   2. ]\\n\\t\\t[ 0.   0.   0.   0.  -3. ]]'), ('net', 'Automatically create QUBO which has value 1 for all connectivity defined by array of edges and graph size N\\n\\t.. code-block:: python\\n\\t\\tprint(wq.net([[0,1],[1,2]],4))\\n\\t\\t#=>\\n\\t\\t[[0. 1. 0. 0.]\\n\\t\\t[0. 0. 1. 0.]\\n\\t\\t[0. 0. 0. 0.]\\n\\t\\t[0. 0. 0. 0.]]\\n\\tthis create 4*4 QUBO and put value 1 on connection between 0th and 1st qubit, 1st and 2nd qubit'), ('opt.plot', 'Draws energy chart using matplotlib.')]\n",
            "Batch 11: 10 successful, 0 failed out of 10 items\n",
            "Processed 120 items in 358.90 seconds. Rate: 0.33 items/sec\n",
            "Creating Hugging Face dataset\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/120 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fbad6e8470dc48578e85b9b8d1dee95e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading dataset to mrinjera/testing...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "daa7c9ae13194c5491a28552c7cb7c7e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1aacc949075a41718af5cdf3bdb4b7a1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading...:   0%|          | 0.00/26.9k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b9d5ab2c97384be286a94fc61d5812e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/382 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a4fbbe1e4b574636b11a90eabc7e0c7c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing batches:  60%|██████    | 12/20 [06:02<04:00, 30.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully uploaded dataset to https://huggingface.co/datasets/mrinjera/testing\n",
            "[('Opt.run', 'Run SA with provided QUBO. \\n\\t\\tSet qubo attribute in advance of calling this method.'), ('numpartition_qaoa', 'Do the Number partition QAOA.\\n\\n    :param n_step: The number of step of QAOA\\n    :param nums: The edges list of the graph.\\n    :returns Vqe object'), ('slicing_singlevalue', 'Internally used.'), ('slicing', 'Internally used.'), ('qubit_pairs', 'Internally used.'), ('get_maximum_index', 'Internally used.'), ('Gate._str_targets', 'Returns printable string of targets.'), ('to_inttuple', 'Convert from bit string likes \\'01011\\' to int tuple likes (0, 1, 0, 1, 1)\\n\\n    Args:\\n        bitstr (str, Counter, dict): String which is written in \"0\" or \"1\".\\n            If all keys are bitstr, Counter or dict are also can be converted by this function.\\n\\n    Returns:\\n        tuple of int, Counter, dict: Converted bits.\\n            If bitstr is Counter or dict, returns the Counter or dict\\n            which contains {converted key: original value}.\\n\\n    Raises:\\n        ValueError: If bitstr type is unexpected or bitstr contains illegal character.'), ('get_scipy_minimizer', 'Get minimizer which uses `scipy.optimize.minimize`'), ('expect', 'For the VQE simulation without sampling.')]\n",
            "Batch 12: 10 successful, 0 failed out of 10 items\n",
            "Processed 130 items in 383.74 seconds. Rate: 0.34 items/sec\n",
            "Creating Hugging Face dataset\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/130 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e2357e502aec4d4e962ed8ae6f49fbf6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading dataset to mrinjera/testing...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "da5a723ee31b400c9880a201cb3535b7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f3f17b282f2489e8046e5cd8177c0fb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading...:   0%|          | 0.00/28.0k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "076ec03ab0ed4a32a38b0b15090e53b3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/382 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5558e90f53c44de3b16eb54799a995ae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing batches:  65%|██████▌   | 13/20 [06:27<03:20, 28.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully uploaded dataset to https://huggingface.co/datasets/mrinjera/testing\n",
            "[('non_sampling_sampler', 'Calculate the expectations without sampling.'), ('get_measurement_sampler', 'Returns a function which get the expectations by sampling the measured circuit'), ('get_state_vector_sampler', 'Returns a function which get the expectations by sampling the state vector'), ('get_qiskit_sampler', 'Returns a function which get the expectation by sampling via Qiskit.\\n\\n    This function requires `qiskit` module.'), ('AnsatzBase.get_energy', 'Calculate energy from circuit and sampler.'), ('AnsatzBase.get_objective', 'Get an objective function to be optimized.'), ('VqeResult.get_probs', 'Get probabilities.'), ('Vqe.result', 'Vqe.result is deprecated. Use `result = Vqe.run()`.'), ('factoring_qaoa', 'Do the Number partition QAOA.\\n\\n    :param num: The number to be factoring.\\n    :param n_step: The number of step of QAOA\\n    :param edges: The edges list of the graph.\\n    :returns result of QAOA'), ('Backend._run_gates', \"Iterate gates and call backend's action for each gates\")]\n",
            "Batch 13: 10 successful, 0 failed out of 10 items\n",
            "Processed 140 items in 415.09 seconds. Rate: 0.34 items/sec\n",
            "Creating Hugging Face dataset\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/140 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "feed39d5904f419dab65d6ce5572ffb9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading dataset to mrinjera/testing...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed0751a5644a4a1d91bb746b1ba23f30"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cfb8bf3989bf48e7941fcda0d37e90d6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading...:   0%|          | 0.00/29.0k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3009f61931884c74be1e08f625275020"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/382 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ba77cb900a434feeb1180ff62f636bcd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing batches:  70%|███████   | 14/20 [06:57<02:54, 29.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully uploaded dataset to https://huggingface.co/datasets/mrinjera/testing\n",
            "[('Backend._run', \"Default implementation of `Backend.run`.\\n        Backend developer shouldn't override this function, but override `run` instead of this.\\n\\n        The default flow of running is:\\n            1. preprocessing\\n            2. call the gate action which defined in backend\\n            3. postprocessing\\n\\n        Backend developer can:\\n            1. Define preprocessing process. Override `_preprocess_run`\\n            2. Define the gate action. Define methods `gate_{gate.lowername}`,\\n               for example, `gate_x` for X gate, `gate_cx` for CX gate.\\n            3. Define postprocessing process (and make return value). Override `_postprocess_run`\\n        Otherwise, the developer can override `run` method if they want to change the flow of run.\"), ('Backend.run', 'Run the backend.'), ('Backend._resolve_fallback', 'Resolve fallbacks and flatten gates.'), ('_NumPyBackendContext.prepare', 'Prepare to run next shot.'), ('_NumPyBackendContext.store_shot', 'Store current cregs to shots_result'), ('Circuit.copy', 'Copy the circuit.\\n\\n        :params\\n        copy_backends :bool copy backends if True.\\n        copy_default_backend :bool copy default_backend if True.'), ('Circuit.run', 'Run the circuit.\\n\\n        `Circuit` have several backends. When `backend` parameter is specified,\\n        use specified backend, and otherwise, default backend is used.\\n        Other parameters are passed to the backend.\\n\\n        The meaning of parameters are depends on the backend specifications.\\n        However, following parameters are commonly used.\\n\\n        Commonly used args (Depends on backend):\\n            shots (int, optional): The number of sampling the circuit.\\n            returns (str, optional):  The category of returns value.\\n                e.g. \"statevector\" returns the state vector after run the circuit.\\n                     \"shots\" returns the counter of measured value.\\n            token, url (str, optional): The token and URL for cloud resource.\\n\\n        Returns:\\n            Depends on backend.\\n\\n        Raises:\\n            Depends on backend.'), ('Circuit.make_cache', 'Make a cache to reduce the time of run. Some backends may implemented it.\\n\\n        This is temporary API. It may changed or deprecated.'), ('Circuit.set_default_backend', 'Set the default backend of this circuit.\\n\\n        This setting is only applied for this circuit.\\n        If you want to change the default backend of all gates,\\n        use `BlueqatGlobalSetting.set_default_backend()`.\\n\\n        After set the default backend by this method,\\n        global setting is ignored even if `BlueqatGlobalSetting.set_default_backend()` is called.\\n        If you want to use global default setting, call this method with backend_name=None.\\n\\n        Args:\\n            backend_name (str or None): new default backend name.\\n                If None is given, global setting is applied.\\n\\n        Raises:\\n            ValueError: If `backend_name` is not registered backend.'), ('BlueqatGlobalSetting.register_macro', 'Register new macro to Circuit.\\n\\n        Args:\\n            name (str): The name of macro.\\n            func (callable): The function to be called.\\n            allow_overwrite (bool, optional): If True, allow to overwrite the existing macro.\\n                Otherwise, raise the ValueError.\\n\\n        Raises:\\n            ValueError: The name is duplicated with existing macro, gate or method.\\n                When `allow_overwrite=True`, this error is not raised.')]\n",
            "Batch 14: 10 successful, 0 failed out of 10 items\n",
            "Processed 150 items in 443.24 seconds. Rate: 0.34 items/sec\n",
            "Creating Hugging Face dataset\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/150 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9619e437a1954c58832d3c4197e84fdd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading dataset to mrinjera/testing...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6eba26a32de94bca89f936c02f427000"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5c833428ea02449f82058ed7f987d1c6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading...:   0%|          | 0.00/31.0k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b987c4bea3c8404c869c972fb1369793"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/382 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4448e374a13c45e4afcc1c48e3ad0b46"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing batches:  75%|███████▌  | 15/20 [07:26<02:24, 28.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully uploaded dataset to https://huggingface.co/datasets/mrinjera/testing\n",
            "[('BlueqatGlobalSetting.register_gate', 'Register new gate to gate set.\\n\\n        Args:\\n            name (str): The name of gate.\\n            gateclass (type): The type object of gate.\\n            allow_overwrite (bool, optional): If True, allow to overwrite the existing gate.\\n                Otherwise, raise the ValueError.\\n\\n        Raises:\\n            ValueError: The name is duplicated with existing gate.\\n                When `allow_overwrite=True`, this error is not raised.'), ('BlueqatGlobalSetting.register_backend', 'Register new backend.\\n\\n        Args:\\n            name (str): The name of backend.\\n            gateclass (type): The type object of backend\\n            allow_overwrite (bool, optional): If True, allow to overwrite the existing backend.\\n                Otherwise, raise the ValueError.\\n\\n        Raises:\\n            ValueError: The name is duplicated with existing backend.\\n                When `allow_overwrite=True`, this error is not raised.'), ('maxcut_qaoa', 'Setup QAOA.\\n\\n    :param n_step: The number of step of QAOA\\n    :param n_sample: The number of sampling time of each measurement in VQE.\\n                     If None, use calculated ideal value.\\n    :param edges: The edges list of the graph.\\n    :returns Vqe object'), ('pauli_from_char', 'Make Pauli matrix from an character.\\n\\n    Args:\\n        ch (str): \"X\" or \"Y\" or \"Z\" or \"I\".\\n        n (int, optional): Make Pauli matrix as n-th qubits.\\n\\n    Returns:\\n        If ch is \"X\" => X, \"Y\" => Y, \"Z\" => Z, \"I\" => I\\n\\n    Raises:\\n        ValueError: When ch is not \"X\", \"Y\", \"Z\" nor \"I\".'), ('commutator', \"Returns [expr1, expr2] = expr1 * expr2 - expr2 * expr1.\\n\\n    Args:\\n        expr1 (Expr, Term or Pauli operator): Pauli's expression.\\n        expr2 (Expr, Term or Pauli operator): Pauli's expression.\\n\\n    Returns:\\n        Expr: expr1 * expr2 - expr2 * expr1.\"), ('is_commutable', \"Test whether expr1 and expr2 are commutable.\\n\\n    Args:\\n        expr1 (Expr, Term or Pauli operator): Pauli's expression.\\n        expr2 (Expr, Term or Pauli operator): Pauli's expression.\\n        eps (float, optional): Machine epsilon.\\n            If |[expr1, expr2]| < eps, consider it is commutable.\\n\\n    Returns:\\n        bool: if expr1 and expr2 are commutable, returns True, otherwise False.\"), ('_PauliImpl.to_matrix', 'Convert to the matrix.'), ('Term.from_pauli', 'Make new Term from an Pauli operator'), ('Term.from_chars', 'Make Pauli\\'s Term from chars which is written by \"X\", \"Y\", \"Z\" or \"I\".\\n        e.g. \"XZIY\" => X(0) * Z(1) * Y(3)\\n\\n        Args:\\n            chars (str): Written in \"X\", \"Y\", \"Z\" or \"I\".\\n\\n        Returns:\\n            Term: A `Term` object.\\n\\n        Raises:\\n            ValueError: When chars conteins the character which is \"X\", \"Y\", \"Z\" nor \"I\".'), ('Term.join_ops', 'For internal use.')]\n",
            "Batch 15: 10 successful, 0 failed out of 10 items\n",
            "Processed 160 items in 472.26 seconds. Rate: 0.34 items/sec\n",
            "Creating Hugging Face dataset\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/160 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "67682c37799746009a2d5c52ac4918d6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading dataset to mrinjera/testing...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a2dd3d58c5c47509011f58200383e4d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "be6e56d4248b456bbecba6b8ac5ef77f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading...:   0%|          | 0.00/32.4k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c70ae589da0a4da2ae951049e16480a9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/382 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dd01f72317ee451dbccb2a0bfe0e7a92"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing batches:  80%|████████  | 16/20 [07:55<01:55, 28.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully uploaded dataset to https://huggingface.co/datasets/mrinjera/testing\n",
            "[('Term.simplify', 'Simplify the Term.'), ('Term.append_to_circuit', 'Append Pauli gates to `Circuit`.'), ('Term.get_time_evolution', 'Get the function to append the time evolution of this term.\\n\\n        Returns:\\n            function(circuit: Circuit, t: float):\\n                Add gates for time evolution to `circuit` with time `t`'), ('Term.to_matrix', 'Convert to the matrix.'), ('Expr.from_terms_dict', 'For internal use.'), ('Expr.is_identity', 'If `self` is I, returns True, otherwise False.'), ('Expr.max_n', 'Returns the maximum index of Pauli matrices in the Term.'), ('Expr.is_all_terms_commutable', 'Test whether all terms are commutable. This function may very slow.'), ('Expr.simplify', 'Simplify the Expr.'), ('Expr.to_matrix', 'Convert to the matrix.')]\n",
            "Batch 16: 10 successful, 0 failed out of 10 items\n",
            "Processed 170 items in 497.11 seconds. Rate: 0.34 items/sec\n",
            "Creating Hugging Face dataset\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/170 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "139624ce641d495f9be9c73775260721"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading dataset to mrinjera/testing...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "61d9ce25c6e94175ad69217fe358c0f9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6df47b2ee09d44f59c7a1c87e01c9bde"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading...:   0%|          | 0.00/33.1k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "03e4503bd2084874955f6d262b07410d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/382 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "afa1633d0b2d4407927ec1ad2cd55db7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing batches:  85%|████████▌ | 17/20 [08:19<01:23, 27.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully uploaded dataset to https://huggingface.co/datasets/mrinjera/testing\n",
            "[('SvgComposedPoly.add_coord', 'Adds a coord to the polyline and creates another circle'), ('SvgPolygon.set_stroke', 'Sets the stroke properties.\\r\\n\\r\\n        Args:\\r\\n            width (int): stroke width\\r\\n            color (str): stroke color'), ('SvgPolygon.add_arrow_coord', 'Determine the coordinates of an arrow head polygon\\r\\n            with height (h) and width (w) and recess (r)\\r\\n            pointing from the one but last to the last point of (poly)line (line).\\r\\n            Note that the coordinates of an SvgLine and an SvgPolyline\\r\\n            are stored in different variables.'), ('MyApp.Draw_a_drawing_of_one_sheet', 'Draw a drawing with two boxes, each with a name inside\\r\\n            and a polyline between the midpoints of the sides of the boxes,\\r\\n            with half-way the polyline a rhombus with an id included.'), ('MyApp.box_type_1', 'Draw a rectangular box of box_width and box_height\\r\\n            with name and ident,\\r\\n            on sheet with (X,Y) as its center on the canvas\\r\\n            Return midpts = N(x,y), S(x,y), E(x,y), W(x,y).'), ('MyApp.rhombus_polygon', 'Draw a rhombus polygon.\\r\\n            Horizontal size (-hor_size, +hor_size) and\\r\\n            vertical size (-vert_size, +vert_size).\\r\\n            with its center on position X,Y\\r\\n            and with its str_id as text in the middle.'), ('MyApp.onerror', 'WebPage Event that occurs on webpage errors'), ('MyApp.onresize', 'WebPage Event that occurs on webpage gets resized'), ('MyApp.My_TreeTable', 'Define and display a table\\n            in which the values in first column form one or more trees.'), ('MyApp.Define_TreeTable', 'Define a TreeTable with a heading row\\n            and optionally a second heading row.')]\n",
            "Batch 17: 10 successful, 0 failed out of 10 items\n",
            "Processed 180 items in 523.64 seconds. Rate: 0.34 items/sec\n",
            "Creating Hugging Face dataset\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/180 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e775dfdeab074a65aa5c19988caf1644"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading dataset to mrinjera/testing...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "919513e6034841e7bf9012075e600e69"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "061ebaf7fee440a99243f3c644eff665"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading...:   0%|          | 0.00/34.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2d424fdb5d6843d286a346e5edc961d2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/382 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ef6689257844249a2ac3b5d6dd74716"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing batches:  90%|█████████ | 18/20 [08:47<00:55, 27.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully uploaded dataset to https://huggingface.co/datasets/mrinjera/testing\n",
            "[('MyApp.Display_TreeTable', \"Display a table in which the values in first column form one or more trees.\\n            The table has row with fields that are strings of identifiers/names.\\n            First convert each row into a row_widget and item_widgets\\n            that are displayed in a TableTree.\\n            Each input row shall start with a parent field (field[0])\\n            that determines the tree hierarchy but that is not displayed on that row.\\n            The parent widget becomes an attribute of the first child widget.\\n            Field[1] is the row color, field[2:] contains the row values.\\n            Top child(s) shall have a parent field value that is blank ('').\\n            The input table rows shall be in the correct sequence.\"), ('InputGauge.confirm_value', 'event called clicking on the gauge and so changing its value.\\n           propagates the new value'), ('Editor.configure_widget_for_editing', 'A widget have to be added to the editor, it is configured here in order to be conformant \\n            to the editor'), ('Cell.on_right_click', 'Here with right click the change of cell is changed'), ('MyApp.build_mine_matrix', 'random fill cells with mines and increments nearest mines num in adiacent cells'), ('MyApp.check_if_win', 'Here are counted the flags. Is checked if the user win.'), ('CookieInterface.set_cookie', 'expiration (int): seconds after with the cookie automatically gets deleted'), ('LoginManager.renew_session', 'Have to be called on user actions to check and renew session'), ('decorate_event_js', \"setup a method as an event, adding also javascript code to generate\\n\\n    Args:\\n        js_code (str): javascript code to generate the event client-side.\\n            js_code is added to the widget html as \\n            widget.attributes['onclick'] = js_code%{'emitter_identifier':widget.identifier, 'event_name':'onclick'}\"), ('decorate_set_on_listener', 'Private decorator for use in the editor.\\n        Allows the Editor to create listener methods.\\n\\n        Args:\\n            params (str): The list of parameters for the listener \\n                method (es. \"(self, new_value)\")')]\n",
            "Batch 18: 10 successful, 0 failed out of 10 items\n",
            "Processed 190 items in 550.09 seconds. Rate: 0.35 items/sec\n",
            "Creating Hugging Face dataset\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/190 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7b0d0f9d8f5249bb9857efddec250ca5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading dataset to mrinjera/testing...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3ea2a1c478a74633b5d502f5c91304d8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "afa2469de89f4497aa6ceb29933e1840"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading...:   0%|          | 0.00/36.4k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "746fb0e30363412cab818485bec37666"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/382 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e84c64b6db974319b887eeec5f454c67"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing batches:  95%|█████████▌| 19/20 [09:13<00:27, 27.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully uploaded dataset to https://huggingface.co/datasets/mrinjera/testing\n",
            "[('ClassEventConnector.do', 'The callback and userdata gets stored, and if there is some javascript to add\\n            the js code is appended as attribute for the event source'), ('Tag.repr', 'It is used to automatically represent the object to HTML format\\n        packs all the attributes, children and so on.\\n\\n        Args:\\n            changed_widgets (dict): A dictionary containing a collection of tags that have to be updated.\\n                The tag that have to be updated is the key, and the value is its textual repr.'), ('Tag.add_child', \"Adds a child to the Tag\\n\\n        To retrieve the child call get_child or access to the Tag.children[key] dictionary.\\n\\n        Args:\\n            key (str):  Unique child's identifier, or iterable of keys\\n            value (Tag, str): can be a Tag, an iterable of Tag or a str. In case of iterable\\n                of Tag is a dict, each item's key is set as 'key' param\"), ('Tag.empty', 'remove all children from the widget'), ('Tag.remove_child', \"Removes a child instance from the Tag's children.\\n\\n        Args:\\n            child (Tag): The child to be removed.\"), ('Widget.set_style', 'Allows to set style properties for the widget.\\n            Args:\\n                style (str or dict): The style property dictionary or json string.'), ('Widget.set_size', \"Set the widget size.\\n\\n        Args:\\n            width (int or str): An optional width for the widget (es. width=10 or width='10px' or width='10%').\\n            height (int or str): An optional height for the widget (es. height=10 or height='10px' or height='10%').\"), ('Widget.repr', 'Represents the widget as HTML format, packs all the attributes, children and so on.\\n\\n        Args:\\n            client (App): Client instance.\\n            changed_widgets (dict): A dictionary containing a collection of widgets that have to be updated.\\n                The Widget that have to be updated is the key, and the value is its textual repr.'), ('Widget.onkeyup', \"Called when user types and releases a key. \\n        The widget should be able to receive the focus in order to emit the event.\\n        Assign a 'tabindex' attribute to make it focusable.\\n        \\n        Args:\\n            key (str): the character value\\n            keycode (str): the numeric char code\"), ('Widget.onkeydown', \"Called when user types and releases a key.\\n        The widget should be able to receive the focus in order to emit the event.\\n        Assign a 'tabindex' attribute to make it focusable.\\n        \\n        Args:\\n            key (str): the character value\\n            keycode (str): the numeric char code\")]\n",
            "Batch 19: 10 successful, 0 failed out of 10 items\n",
            "Processed 200 items in 578.34 seconds. Rate: 0.35 items/sec\n",
            "Creating Hugging Face dataset\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd52c23c9663404899e323e940eabe93"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading dataset to mrinjera/testing...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1639e59c6ba34bbc85f5c4348b0f0aa0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b33b56c86a5460f91ce72f91d65a833"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading...:   0%|          | 0.00/37.9k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3055acd9a0244a5fb45c8d64606a1fb9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/382 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4e2a8c7faba54b14a6e5bad46df19c83"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing batches: 100%|██████████| 20/20 [09:42<00:00, 29.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully uploaded dataset to https://huggingface.co/datasets/mrinjera/testing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "    print(train_data[i]['func_documentation_string'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "z2i8fQR37YCJ",
        "outputId": "963e6984-8945-4bed-897e-b03ea494469a"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Check that the WebSocket connection is open.\n",
            "\n",
            "        Raise :exc:`~websockets.exceptions.ConnectionClosed` if it isn't.\n",
            "Read incoming messages and put them in a queue.\n",
            "\n",
            "        This coroutine runs in a task until the closing handshake is started.\n",
            "Read a single message from the connection.\n",
            "\n",
            "        Re-assemble data frames if the message is fragmented.\n",
            "\n",
            "        Return ``None`` when the closing handshake is started.\n",
            "Read a single data frame from the connection.\n",
            "\n",
            "        Process control frames received before the next data frame.\n",
            "\n",
            "        Return ``None`` if a close frame is encountered before any data frame.\n",
            "Read a single frame from the connection.\n",
            "Write a close frame if and only if the connection state is OPEN.\n",
            "\n",
            "        This dedicated coroutine must be used for writing close frames to\n",
            "        ensure that at most one close frame is sent on a given connection.\n",
            "Send a Ping frame and wait for a Pong frame at regular intervals.\n",
            "\n",
            "        This coroutine exits when the connection terminates and one of the\n",
            "        following happens:\n",
            "        - :meth:`ping` raises :exc:`ConnectionClosed`, or\n",
            "        - :meth:`close_connection` cancels :attr:`keepalive_ping_task`.\n",
            "7.1.1. Close the WebSocket Connection\n",
            "\n",
            "        When the opening handshake succeeds, :meth:`connection_open` starts\n",
            "        this coroutine in a task. It waits for the data transfer phase to\n",
            "        complete then it closes the TCP connection cleanly.\n",
            "\n",
            "        When the opening handshake fails, :meth:`fail_connection` does the\n",
            "        same. There's no data transfer phase in that case.\n",
            "Wait until the TCP connection is closed or ``self.close_timeout`` elapses.\n",
            "\n",
            "        Return ``True`` if the connection is closed and ``False`` otherwise.\n",
            "7.1.7. Fail the WebSocket Connection\n",
            "\n",
            "        This requires:\n",
            "\n",
            "        1. Stopping all processing of incoming data, which means cancelling\n",
            "           :attr:`transfer_data_task`. The close code will be 1006 unless a\n",
            "           close frame was received earlier.\n",
            "\n",
            "        2. Sending a close frame with an appropriate code if the opening\n",
            "           handshake succeeded and the other side is likely to process it.\n",
            "\n",
            "        3. Closing the connection. :meth:`close_connection` takes care of\n",
            "           this once :attr:`transfer_data_task` exits after being canceled.\n",
            "\n",
            "        (The specification describes these steps in the opposite order.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "vBQ6cwTbpchW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "from datasets import Dataset, load_dataset\n",
        "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
        "from sentence_transformers.evaluation import InformationRetrievalEvaluator\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import logging\n",
        "from typing import List, Dict, Tuple\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "DATASET_NAME = \"mrinjera/testing\"\n",
        "HF_TOKEN = userdata.get(\"HUGGING_FACE_TOKEN\")\n",
        "MODEL_NAME = \"microsoft/codebert-base\"\n",
        "OUTPUT_MODEL_PATH = \"./sbert-function-retrieval\"\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 4\n",
        "LEARNING_RATE = 2e-5\n",
        "WARMUP_STEPS = 1000\n",
        "EVALUATION_STEPS = 5000"
      ],
      "metadata": {
        "id": "SNteRSuHwyaM"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_process_dataset(dataset_name: str, token: str) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    \"\"\"Load the dataset and process it for training.\"\"\"\n",
        "    print(f\"Loading dataset: {dataset_name}\")\n",
        "\n",
        "    dataset = load_dataset(dataset_name, token=token)\n",
        "\n",
        "    #TODO: for clarity, have a bool param that controls the behavior\n",
        "    if 'train' not in dataset or 'test' not in dataset:\n",
        "        dataset = dataset['train'].shuffle(seed=42)\n",
        "        train_size = int(0.8 * len(dataset))\n",
        "        train_df = dataset.select(range(train_size)).to_pandas()\n",
        "        test_df = dataset.select(range(train_size, len(dataset))).to_pandas()\n",
        "    else:\n",
        "        train_df = dataset['train'].to_pandas()\n",
        "        test_df  = dataset['test'].to_pandas()\n",
        "\n",
        "    print(f\"Train dataset loaded with {len(train_df)} examples\")\n",
        "    print(f\"Test dataset loaded with {len(test_df)} examples\")\n",
        "    print(f\"Dataset columns: {train_df.columns.tolist()}\")\n",
        "\n",
        "    required_columns = ['function_name', 'docstring', 'question', 'id']\n",
        "    for df_name, df in [('train', train_df), ('test', test_df)]:\n",
        "        missing_columns = [col for col in required_columns if col not in df.columns]\n",
        "        if missing_columns:\n",
        "            raise ValueError(f\"Missing required columns in {df_name} split: {missing_columns}\")\n",
        "\n",
        "    train_df = train_df.dropna(subset=['docstring', 'question'])\n",
        "    test_df = test_df.dropna(subset=['docstring', 'question'])\n",
        "\n",
        "    print(f\"After removing missing values:\")\n",
        "    print(f\"  Train: {len(train_df)} examples\")\n",
        "    print(f\"  Test: {len(test_df)} examples\")\n",
        "\n",
        "    return train_df, test_df"
      ],
      "metadata": {
        "id": "f_Nn2FS-zNjD"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_training_examples(df: pd.DataFrame) -> List[InputExample]:\n",
        "    \"\"\"Create InputExample objects for SBERT training.\"\"\"\n",
        "    examples = []\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        # Create input example with question as query and docstring as positive document\n",
        "        example = InputExample(\n",
        "            texts=[row['question'], row['docstring']],\n",
        "            label=1.0  # Positive pair\n",
        "        )\n",
        "        examples.append(example)\n",
        "\n",
        "    print(f\"Created {len(examples)} training examples\")\n",
        "    return examples\n",
        "\n",
        "def create_evaluation_data(df: pd.DataFrame) -> Tuple[Dict[str, str], Dict[str, str], Dict[str, set]]:\n",
        "    \"\"\"Create evaluation data for Information Retrieval evaluation.\"\"\"\n",
        "    # Split data for evaluation\n",
        "    eval_df = df.sample(n=min(1000, len(df) // 10), random_state=42)\n",
        "\n",
        "    queries = {}\n",
        "    corpus = {}\n",
        "    relevant_docs = {}\n",
        "\n",
        "    for idx, row in eval_df.iterrows():\n",
        "        query_id = f\"q_{idx}\"\n",
        "        doc_id = f\"d_{idx}\"\n",
        "\n",
        "        queries[query_id] = row['question']\n",
        "        corpus[doc_id] = row['docstring']\n",
        "        relevant_docs[query_id] = {doc_id}\n",
        "\n",
        "    print(f\"Created evaluation data with {len(queries)} queries and {len(corpus)} documents\")\n",
        "    return queries, corpus, relevant_docs\n",
        "\n",
        "def create_validation_split(train_df: pd.DataFrame,\n",
        "                          validation_size: float = 0.1) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    \"\"\"Create a validation split from training data for monitoring during training.\"\"\"\n",
        "    train_split, val_split = train_test_split(\n",
        "        train_df,\n",
        "        test_size=validation_size,\n",
        "        random_state=42,\n",
        "        stratify=None\n",
        "    )\n",
        "\n",
        "    print(f\"Created validation split:\")\n",
        "    print(f\"  Training: {len(train_split)} examples\")\n",
        "    print(f\"  Validation: {len(val_split)} examples\")\n",
        "\n",
        "    return train_split, val_split"
      ],
      "metadata": {
        "id": "YNicopkCpfHS"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_model(model_name: str) -> SentenceTransformer:\n",
        "    \"\"\"Initialize the SBERT model.\"\"\"\n",
        "    print(f\"Initializing model: {model_name}\")\n",
        "\n",
        "    model = SentenceTransformer(model_name)\n",
        "\n",
        "    print(f\"Model max sequence length: {model.max_seq_length}\")\n",
        "    print(f\"Model device: {model.device}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "def train_model(model: SentenceTransformer,\n",
        "                train_examples: List[InputExample],\n",
        "                val_queries: Dict[str, str],\n",
        "                val_corpus: Dict[str, str],\n",
        "                val_relevant_docs: Dict[str, set],\n",
        "                device: torch.device) -> SentenceTransformer:\n",
        "    \"\"\"Train the SBERT model with Multiple Negatives Ranking Loss.\"\"\"\n",
        "\n",
        "    train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=BATCH_SIZE)\n",
        "\n",
        "    train_loss = losses.MultipleNegativesRankingLoss(model)\n",
        "\n",
        "    val_evaluator = InformationRetrievalEvaluator(\n",
        "        queries=val_queries,\n",
        "        corpus=val_corpus,\n",
        "        relevant_docs=val_relevant_docs,\n",
        "        name=\"validation-eval\"\n",
        "    )\n",
        "\n",
        "    # calculate warmup steps\n",
        "    num_train_steps = len(train_dataloader) * EPOCHS\n",
        "    warmup_steps = min(WARMUP_STEPS, num_train_steps // 10)\n",
        "\n",
        "    print(f\"Training configuration:\")\n",
        "    print(f\"  Batch size: {BATCH_SIZE}\")\n",
        "    print(f\"  Epochs: {EPOCHS}\")\n",
        "    print(f\"  Learning rate: {LEARNING_RATE}\")\n",
        "    print(f\"  Warmup steps: {warmup_steps}\")\n",
        "    print(f\"  Total training steps: {num_train_steps}\")\n",
        "    print(f\"  Evaluation steps: {EVALUATION_STEPS}\")\n",
        "\n",
        "    model.fit(\n",
        "        train_objectives=[(train_dataloader, train_loss)],\n",
        "        evaluator=val_evaluator,\n",
        "        epochs=EPOCHS,\n",
        "        evaluation_steps=EVALUATION_STEPS,\n",
        "        warmup_steps=warmup_steps,\n",
        "        output_path=OUTPUT_MODEL_PATH,\n",
        "        optimizer_params={'lr': LEARNING_RATE},\n",
        "        save_best_model=True,\n",
        "        show_progress_bar=True\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "iQQA0sAAwsfN"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_on_test_set(model: SentenceTransformer,\n",
        "                        test_queries: Dict[str, str],\n",
        "                        test_corpus: Dict[str, str],\n",
        "                        test_relevant_docs: Dict[str, set]) -> Dict[str, float]:\n",
        "    \"\"\"Evaluate the trained model on the test set.\"\"\"\n",
        "    print(\"Evaluating model on test set...\")\n",
        "\n",
        "    # Create test evaluator\n",
        "    test_evaluator = InformationRetrievalEvaluator(\n",
        "        queries=test_queries,\n",
        "        corpus=test_corpus,\n",
        "        relevant_docs=test_relevant_docs,\n",
        "        name=\"test-eval\"\n",
        "    )\n",
        "\n",
        "    # Evaluate\n",
        "    test_score = test_evaluator(model, output_path=OUTPUT_MODEL_PATH)\n",
        "\n",
        "    print(f\"Test evaluation completed. Score: {test_score}\")\n",
        "    return test_score"
      ],
      "metadata": {
        "id": "xOmdmar48opH"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "train_df, test_df = load_and_process_dataset(DATASET_NAME, HF_TOKEN)\n",
        "\n",
        "train_split_df, val_split_df = create_validation_split(train_df)\n",
        "\n",
        "train_examples = create_training_examples(train_split_df)\n",
        "\n",
        "val_queries, val_corpus, val_relevant_docs = create_evaluation_data(val_split_df)\n",
        "\n",
        "test_queries, test_corpus, test_relevant_docs = create_evaluation_data(test_df)\n",
        "\n",
        "\n",
        "# model = initialize_model(MODEL_NAME)\n",
        "\n",
        "# trained_model = train_model(\n",
        "#     model=model,\n",
        "#     train_examples=train_examples,\n",
        "#     val_queries=val_queries,\n",
        "#     val_corpus=val_corpus,\n",
        "#     val_relevant_docs=val_relevant_docs,\n",
        "#     device=device\n",
        "# )\n",
        "\n",
        "# # Load best model for final evaluation\n",
        "# best_model = SentenceTransformer(OUTPUT_MODEL_PATH)\n",
        "\n",
        "# # Evaluate on test set\n",
        "# test_score = evaluate_on_test_set(\n",
        "#     model=best_model,\n",
        "#     test_queries=test_queries,\n",
        "#     test_corpus=test_corpus,\n",
        "#     test_relevant_docs=test_relevant_docs\n",
        "# )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CEAbZYLzT7d",
        "outputId": "b0d514c3-45d2-4da7-d206-597be53b2030"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset: mrinjera/testing\n",
            "Train dataset loaded with 160 examples\n",
            "Test dataset loaded with 40 examples\n",
            "Dataset columns: ['function_name', 'docstring', 'question', 'id']\n",
            "After removing missing values:\n",
            "  Train: 160 examples\n",
            "  Test: 40 examples\n",
            "Created validation split:\n",
            "  Training: 144 examples\n",
            "  Validation: 16 examples\n",
            "Created 144 training examples\n",
            "Created evaluation data with 1 queries and 1 documents\n",
            "Created evaluation data with 4 queries and 4 documents\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ipLdt7WKAhOd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
